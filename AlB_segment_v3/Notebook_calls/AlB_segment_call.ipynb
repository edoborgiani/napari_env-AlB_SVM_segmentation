{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3921d7e7-a91f-4811-9909-c5dfa606f765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cad7ff8-ccf0-489e-ab8c-8456f6a47914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ellipse_pixels(imarray, center, semi_axes, rotation, image_shape):\n",
    "    \"\"\"\n",
    "    Generate the pixel coordinates that lie inside an ellipse.\n",
    "\n",
    "    Parameters:\n",
    "    - center: Tuple (x, y) representing the center of the ellipse.\n",
    "    - semi_axes: Tuple (semi_major_axis, semi_minor_axis) representing the lengths of the ellipse's axes.\n",
    "    - rotation: Rotation angle of the ellipse in radians.\n",
    "    - image_shape: Shape of the image (height, width) to constrain the ellipse.\n",
    "\n",
    "    Returns:\n",
    "    - A 2D array of pixel coordinates (row, column) that lie inside the ellipse.\n",
    "    \"\"\"\n",
    "    # Create a grid of x and y coordinates for the image\n",
    "    y, x = np.meshgrid(np.arange(imarray.shape[1]), np.arange(imarray.shape[0]), indexing='xy')\n",
    "    \n",
    "    # Compute the cosine and sine of the rotation angle\n",
    "    cos_theta = np.cos(rotation)\n",
    "    sin_theta = np.sin(rotation)\n",
    "    \n",
    "    # Rotate the x and y coordinates to align with the ellipse's axes\n",
    "    x_rot = cos_theta * (x - center[0]) + sin_theta * (y - center[1])\n",
    "    y_rot = -sin_theta * (x - center[0]) + cos_theta * (y - center[1])\n",
    "\n",
    "    # Create a mask for pixels that lie inside the ellipse\n",
    "    mask = (x_rot / semi_axes[0])**2 + (y_rot / semi_axes[1])**2 <= 1\n",
    "\n",
    "    # Enable interactive mode for Napari (if needed)\n",
    "    settings.application.ipy_interactive = True\n",
    "\n",
    "    # Return the coordinates of the pixels inside the ellipse\n",
    "    return np.column_stack(np.where(mask))\n",
    "\n",
    "def rgb_to_hsv(rgb_array):\n",
    "    \"\"\"\n",
    "    Convert an array of RGB values to HSV (Hue, Saturation, Value).\n",
    "\n",
    "    Parameters:\n",
    "    - rgb_array: A 2D array where each row is an RGB triplet (R, G, B).\n",
    "\n",
    "    Returns:\n",
    "    - A 2D array where each row is an HSV triplet (H, S, V).\n",
    "      H is in degrees (0-360), S and V are percentages (0-100).\n",
    "    \"\"\"\n",
    "    hsv_list = []\n",
    "    for rgb in rgb_array:\n",
    "        r, g, b = rgb  # Extract the RGB components\n",
    "        h, s, v = colorsys.rgb_to_hsv(r, g, b)  # Convert RGB to HSV\n",
    "        hsv_list.append([h * 360, s * 100, v * 100])  # Scale H to degrees, S and V to percentages\n",
    "    return np.array(hsv_list)\n",
    "\n",
    "def csv_to_matrix(file_path):\n",
    "    \"\"\"\n",
    "    Read a CSV file and convert its contents into a matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "    - A 2D list where each row corresponds to a row in the CSV file.\n",
    "    \"\"\"\n",
    "    matrix = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            # Convert numeric values to integers, leave others as strings\n",
    "            matrix.append([int(value) if value.replace('.', '', 1).isdigit() else value for value in row])\n",
    "    return matrix\n",
    "\n",
    "def classify_points(cloud_points, test_points, bandwidth=1.0):\n",
    "    \"\"\"\n",
    "    Classify test points based on their similarity to a cloud of points using Kernel Density Estimation (KDE).\n",
    "\n",
    "    Parameters:\n",
    "    - cloud_points: A 2D array of points representing the training data.\n",
    "    - test_points: A 2D array of points to classify.\n",
    "    - bandwidth: Bandwidth parameter for the KDE (controls smoothness).\n",
    "\n",
    "    Returns:\n",
    "    - A 1D array of probabilities for each test point.\n",
    "    \"\"\"\n",
    "    # Fit a Kernel Density Estimator to the cloud points\n",
    "    kde = KernelDensity(bandwidth=bandwidth, kernel='gaussian')\n",
    "    kde.fit(cloud_points)\n",
    "    \n",
    "    # Evaluate the probability density for each test point\n",
    "    log_density = kde.score_samples(test_points)\n",
    "    \n",
    "    # Convert log-density to probabilities\n",
    "    probabilities = np.exp(log_density)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9de469-3afa-4dde-a459-45a9fb67a321",
   "metadata": {},
   "source": [
    "## File upload\n",
    "Write the name of the file that needs to be investigated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41837bd-55ba-4b37-affd-bc756542813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the file name without the extension\n",
    "tiff_stem = os.path.splitext(os.path.basename(tiff_file))[0]\n",
    "\n",
    "# Open the TIFF file as an image\n",
    "img=Image.open('./Input_images/' + tiff_file)\n",
    "\n",
    "# Convert the image to a NumPy array for further processing\n",
    "imarray = np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebff832-baa6-468b-8548-8803158d5b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_X=0.698 #um, 10X\n",
    "r_Y=0.698 #um, 10X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457a965b-6f9b-40dd-ae6f-4a8bbcedd6a4",
   "metadata": {},
   "source": [
    "## ROI \n",
    "This section will find the region of interest by checking the blue part. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c9524e-d16c-46ab-a027-5c23c99644cf",
   "metadata": {},
   "source": [
    "#### If the image is RGBA and we only want RGB, remove A channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01697f9d-029d-4a87-9323-c8df04bd58f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove alpha channel if present\n",
    "if imarray.shape[2] == 4:\n",
    "    imarray = imarray[:, :, :3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d835546a-c8d8-478e-ad3e-c4228fa84c9f",
   "metadata": {},
   "source": [
    "Variables: [step] will dictate the size of the square of investigation (smaller values will get a better resolution but slower run), [delta] will dictate the sensitivity of the blue level (smaller values lead to more false positive but higher values lead to more false negative).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b68c90f-af3e-4417-acf3-13d1943683ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the original image to define the ROI (Region of Interest)\n",
    "ROI_image = imarray.copy()\n",
    "\n",
    "# Initialize a mask image with the same dimensions as the green channel of the original image\n",
    "mask_image = np.zeros(np.shape(imarray[:, :, 1]))\n",
    "\n",
    "# Iterate through the image in steps to identify blue-dominant regions\n",
    "for i in range(1 + step, imarray.shape[0], step):\n",
    "    for j in range(1 + step, imarray.shape[1], step):\n",
    "        # Check if the blue channel is dominant over both red and green channels\n",
    "        if (\n",
    "            np.mean(imarray[i-step:i+step, j-step:j+step, 2]) >= delta + np.mean(imarray[i-step:i+step, j-step:j+step, 1]) and\n",
    "            np.mean(imarray[i-step:i+step, j-step:j+step, 2]) >= delta + np.mean(imarray[i-step:i+step, j-step:j+step, 0])\n",
    "        ):\n",
    "            # Mark the region as part of the mask\n",
    "            mask_image[i:i+step, j:j+step] = 1\n",
    "\n",
    "for i in range(1, imarray.shape[0]-1, 1):\n",
    "    for j in range(1, imarray.shape[1]-1, 1):\n",
    "        step_x=5 \n",
    "        step_y=5\n",
    "        if mask_image[i,j]==1:\n",
    "            if i<step_x:\n",
    "                step_x=i\n",
    "            elif i>(imarray.shape[0]-step_x):\n",
    "                step_x=imarray.shape[0]-i\n",
    "            if j<step_y:\n",
    "                step_y=j\n",
    "            elif j>(imarray.shape[1]-step_y):\n",
    "                step_y=imarray.shape[1]-j\n",
    "\n",
    "            bright_image=np.mean(imarray[i-step_x:i+step_x, j-step_y:j+step_y,:])\n",
    "            \n",
    "            for h in [0,1,2]:\n",
    "                if (ROI_image[i,j,h]-int(bright_image-bright_train))<256:\n",
    "                    ROI_image[i,j,h]=ROI_image[i,j,h]-int(bright_image-bright_train)\n",
    "                else:\n",
    "                    ROI_image[i,j,h]=255\n",
    "\n",
    "\n",
    "# Fill small holes in the mask to create a more continuous region\n",
    "mask_filled = remove_small_holes(mask_image.astype(int), area_threshold=holes_threshold, connectivity=1)\n",
    "\n",
    "# Remove small isolated objects from the mask\n",
    "mask_filled = remove_small_objects(mask_filled, min_size=island_threshold, connectivity=1)\n",
    "\n",
    "# Apply the mask to the original image to isolate the ROI\n",
    "ROI_image = ROI_image * np.stack([mask_filled] * 3, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29edae86-68b0-4f8a-896e-c99018aaad60",
   "metadata": {},
   "source": [
    "After you run the next section, a new Napari window will appear with highlighted in green all the nuclei in the ROI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e118b5-582a-4abc-8ffc-75c9140e1bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable interactive mode for Napari\n",
    "settings.application.ipy_interactive = True\n",
    "\n",
    "# Create a copy of the ROI image for processing\n",
    "imarray0 = ROI_image.copy()\n",
    "\n",
    "# Extract the red, green, and blue channels from the ROI image\n",
    "imR = imarray0[:, :, 0]\n",
    "imG = imarray0[:, :, 1]\n",
    "imB = imarray0[:, :, 2]\n",
    "\n",
    "# Convert the training points from RGB to HSV\n",
    "yes_points_hsv = rgb_to_hsv(yes_points)\n",
    "\n",
    "# Scale the HSV training points for better performance in the SVM\n",
    "scaler = StandardScaler()\n",
    "yes_points_scaled = scaler.fit_transform(yes_points_hsv)\n",
    "\n",
    "# Set up the One-Class SVM for anomaly detection\n",
    "sensitivity = 0.7  # Sensitivity level (e.g., 10% of points allowed as outliers)\n",
    "clf = OneClassSVM(kernel='rbf', nu=sensitivity, gamma='scale')\n",
    "clf.fit(yes_points_scaled)\n",
    "\n",
    "# Initialize an empty array for the violet channel\n",
    "imV = np.zeros(np.shape(imR))\n",
    "\n",
    "# Initialize a counter for progress tracking\n",
    "tval = 0\n",
    "\n",
    "# Iterate through the image to classify each pixel\n",
    "for i in range(step, np.shape(imV)[0]):\n",
    "    for j in range(step, np.shape(imV)[1]):\n",
    "        tval += 1\n",
    "        # Process only pixels within the mask\n",
    "        if mask_filled[i, j] > 0:\n",
    "            # Extract RGB values of the current pixel\n",
    "            pR = imR[i, j]\n",
    "            pG = imG[i, j]\n",
    "            pB = imB[i, j]\n",
    "            X = np.array([[pR, pG, pB]])\n",
    "\n",
    "            # Convert the pixel to HSV and scale it\n",
    "            X_hsv = rgb_to_hsv(X)\n",
    "            X_scaled = scaler.transform(X_hsv)\n",
    "\n",
    "            # Classify the pixel using the KDE-based classifier\n",
    "            predictions = classify_points(yes_points, X, bandwidth=20.0)\n",
    "\n",
    "            # Assign the prediction value to the violet channel\n",
    "            if predictions > 0.0:\n",
    "                imV[i, j] = predictions[0]\n",
    "            else:\n",
    "                imV[i, j] = 0\n",
    "        else:\n",
    "            j += step  # Skip to the next step if outside the mask\n",
    "\n",
    "        # Display progress at regular intervals\n",
    "        if (100.0 * tval / (np.shape(imV)[0] * np.shape(imV)[1]) % 1.0 == 0.0):\n",
    "            clear_output(wait=True)\n",
    "            print('PROGRESS ' + str(100.0 * tval / (np.shape(imV)[0] * np.shape(imV)[1])) + ' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c20e504-9bab-44ee-b218-15966098e140",
   "metadata": {},
   "source": [
    "#### Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c042dd-0f27-4d7f-b201-5d6c0875496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#🔹 Step 1: Thresholding: switch from grayscale to binary scale (different brightness to either 0 for background or 1 for nuclei)\n",
    "im_in=imV\n",
    "\n",
    "# Get all nonzero values in imV (ignoring background)\n",
    "valid_pixels = imV[imV > 0]  \n",
    "\n",
    "# Compute the 98th percentile threshold only for these valid pixels\n",
    "if len(valid_pixels) > 0:  # Ensure there are nonzero pixels\n",
    "    threshold_value = np.percentile(valid_pixels, 99.0)  \n",
    "    binary_mask = (imV >= threshold_value)  # Keep only the top 2% brightest pixels\n",
    "else:\n",
    "    binary_mask = np.zeros_like(imV)  # If no valid pixels, return empty mask\n",
    "\n",
    "im_out=binary_mask.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479f0490-1dfb-4645-a7a9-60ec7752783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Remove Noise & Artifacts\n",
    "im_in=im_out\n",
    "binary_mask=im_in\n",
    "\n",
    "binary_mask2 = remove_small_objects(binary_mask, min_size=5)  \n",
    "binary_mask2 = closing(binary_mask2, square(3))  # Fills small holes and connects nearby white regions.\n",
    "\n",
    "im_out=binary_mask2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe4810b-d433-4c1d-88d6-d371e6fbffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Remove Artifacts Based on Size\n",
    "im_in=im_out\n",
    "binary_mask_2=im_in\n",
    "\n",
    "# Define the minimum and maximum size for nuclei to be considered valid\n",
    "min_nucleus_diam = 3  # Minimum diameter of a nucleus (um)\n",
    "max_nucleus_diam = 25  # Maximum diameter of a nucleus (um)\n",
    "\n",
    "min_nucleus_diam_res = min_nucleus_diam/((r_X+r_Y)/2)\n",
    "max_nucleus_diam_res = max_nucleus_diam/((r_X+r_Y)/2)\n",
    "\n",
    "min_nucleus_size=(min_nucleus_diam/2)*(min_nucleus_diam/2)*np.pi\n",
    "max_nucleus_size=(max_nucleus_diam/2)*(max_nucleus_diam/2)*np.pi\n",
    "\n",
    "# Initialize an empty mask to store the filtered regions\n",
    "filtered_mask = np.zeros_like(binary_mask2)\n",
    "\n",
    "# Iterate through each connected region in the labeled binary mask\n",
    "for region in regionprops(label(binary_mask2)):\n",
    "    # Check if the region's area falls within the valid size range\n",
    "    if min_nucleus_size <= region.area <= max_nucleus_size:\n",
    "        # Add the region to the filtered mask\n",
    "        filtered_mask[label(binary_mask2) == region.label] = 1\n",
    "\n",
    "im_out=filtered_mask.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a61845-c07a-4f69-a5fe-171c69214145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Watershed for Better Separation\n",
    "im_in=im_out\n",
    "filtered_mask=im_in\n",
    "\n",
    "# Compute the distance transform of the filtered mask\n",
    "distance = distance_transform_edt(filtered_mask)\n",
    "\n",
    "# Create markers for the watershed algorithm based on the distance transform\n",
    "# Markers are created where the distance is greater than a small fraction of the maximum distance\n",
    "markers = label(distance > 0.0001 * distance.max())\n",
    "\n",
    "# Apply the watershed algorithm to segment nuclei\n",
    "# The negative distance is used to ensure that the watershed grows from the markers\n",
    "segmented_nuclei = watershed(-distance, markers, mask=filtered_mask)\n",
    "\n",
    "im_out=segmented_nuclei.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f7d54b-2fe2-42d6-a369-a7cef7a7a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#🔹 Step 5: Filter by Roundness (Elongation Ratio)\n",
    "im_in=im_out\n",
    "segmented_nuclei=im_in\n",
    "\n",
    "# Define the maximum allowed elongation ratio for roundness filtering\n",
    "max_ratio = 3.0  # Maximum allowed elongation ratio (major_axis / minor_axis)\n",
    "\n",
    "# Initialize an empty mask to store the filtered segments\n",
    "filtered_segments = np.zeros_like(segmented_nuclei)  # Empty mask for valid segments\n",
    "\n",
    "# Initialize a counter for assigning new labels to filtered segments\n",
    "k = 1\n",
    "\n",
    "# Iterate through each connected region in the segmented nuclei\n",
    "for region in regionprops(segmented_nuclei):\n",
    "    # Ensure the minor axis length is greater than zero to avoid division by zero\n",
    "    if region.minor_axis_length > 0:\n",
    "        # Calculate the elongation ratio (major axis length / minor axis length)\n",
    "        elongation_ratio = region.major_axis_length / region.minor_axis_length\n",
    "        \n",
    "        # Check if the elongation ratio is within the acceptable range\n",
    "        if elongation_ratio <= max_ratio:\n",
    "            # Assign a new label to the region in the filtered segments mask\n",
    "            filtered_segments[segmented_nuclei == region.label] = k\n",
    "            k += 1  # Increment the label counter\n",
    "\n",
    "im_out=filtered_segments.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0583a406-631b-4df5-a014-7654aab4ef09",
   "metadata": {},
   "source": [
    "### Output \n",
    "Creates a .tiff file with multiple pages. P1 is the original image, P2 is the ROI chosen as the tissue, P3 is the detected nuclei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53d4253-87d2-4242-b275-de897e0613c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the original image array to an RGB image\n",
    "rgb_im = Image.fromarray(imarray.astype(np.uint8), mode=\"RGB\")\n",
    "\n",
    "# Convert the ROI image array to an RGB image\n",
    "rgb0_im = Image.fromarray(imarray0.astype(np.uint8), mode=\"RGB\")\n",
    "\n",
    "# Initialize an empty RGB array for the filtered segments\n",
    "filtered_segments_rgb = np.zeros((np.shape(filtered_segments)[0], np.shape(filtered_segments)[1], 3))\n",
    "\n",
    "# Generate random colors for each segment label\n",
    "cmd = np.random.rand(np.max(filtered_segments) + 1, 3)\n",
    "cmd[0, :] = [0.0, 0.0, 0.0]  # Ensure the background (label 0) is black\n",
    "\n",
    "# Assign colors to each pixel based on its segment label\n",
    "for i in range(1, np.shape(filtered_segments)[0]):\n",
    "    for j in range(1, np.shape(filtered_segments)[1]):\n",
    "        filtered_segments_rgb[i, j, 0] = int(cmd[filtered_segments[i, j], 0] * 255.0)  # Red channel\n",
    "        filtered_segments_rgb[i, j, 1] = int(cmd[filtered_segments[i, j], 1] * 255.0)  # Green channel\n",
    "        filtered_segments_rgb[i, j, 2] = int(cmd[filtered_segments[i, j], 2] * 255.0)  # Blue channel\n",
    "\n",
    "# Convert the RGB array to uint8 format\n",
    "filtered_segments_rgb = filtered_segments_rgb.astype('uint8')\n",
    "\n",
    "# Convert the filtered segments RGB array to an image\n",
    "b_im = Image.fromarray(filtered_segments_rgb, mode=\"RGB\")\n",
    "\n",
    "# Save the original image, ROI image, and filtered segments image in a single multi-page TIFF file\n",
    "output_path = \"./Output_files/\" + tiff_stem + \"_output.tiff\"\n",
    "rgb_im.save(output_path, save_all=True, append_images=[rgb0_im, b_im])\n",
    "\n",
    "# Print the output file path\n",
    "print(f\"TIFF file saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8791ded5-6ba5-4926-a633-a830f6879410",
   "metadata": {},
   "source": [
    "### QUANTIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0c9eeb-cf73-48ff-b210-566762a7dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import label, center_of_mass\n",
    "\n",
    "# Get unique labels from the filtered segments (excluding the background label 0)\n",
    "labels = np.unique(filtered_segments)\n",
    "labels = labels[labels != 0]\n",
    "\n",
    "# Print the total number of nuclei detected\n",
    "print('TOTAL NUCLEI ' + str(len(labels+1)))\n",
    "\n",
    "# Compute the centroids (barycenters) of each nucleus\n",
    "barycenters = {label: center_of_mass(filtered_segments == label) for label in labels}\n",
    "\n",
    "# Compute the area of each nucleus in square micrometers\n",
    "areas = {label: np.sum(filtered_segments == label) * r_X * r_Y for label in labels}\n",
    "\n",
    "# Convert barycenters to a dictionary of coordinates in micrometers\n",
    "barycenter_coords = {k: (round(v[0], 2) * r_X, round(v[1], 2) * r_Y) for k, v in barycenters.items()}\n",
    "\n",
    "# Calculate the total area of the image in square micrometers\n",
    "fullA = np.prod(np.shape(mask_image)) * r_X * r_Y\n",
    "\n",
    "# Calculate the total area of the ROI in square micrometers\n",
    "roiA = np.sum(mask_image) * r_X * r_Y\n",
    "\n",
    "# Print the total area of the image and the ROI\n",
    "print(\"TOTAL AREA IMAGE %.2e um2\" % fullA)\n",
    "print(\"TOTAL AREA ROI %.2e um2\" % roiA)\n",
    "\n",
    "# Calculate the concentration of cells in the ROI (cells per square micrometer)\n",
    "roiCON = (len(labels+1)) / roiA\n",
    "\n",
    "# Print the cell concentration in the ROI\n",
    "print(\"CELL CONCENTRATION in ROI %.2e cells/um2\" % roiCON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6d8187-8d56-4473-b7ef-1c98ca4c715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Excel workbook\n",
    "workbook = xlsxwriter.Workbook(\"./Output_files/\" + tiff_stem + \".xlsx\")\n",
    "\n",
    "## FORMATS\n",
    "# Define a format for headers (bold text with yellow background)\n",
    "header = workbook.add_format({'bold': True})\n",
    "header.set_bg_color('yellow')\n",
    "\n",
    "# Define a format for floating-point numbers\n",
    "floats = workbook.add_format({'num_format': '0.00'})\n",
    "\n",
    "# Define a format for exponential numbers\n",
    "exp = workbook.add_format()\n",
    "exp.set_num_format(11)\n",
    "\n",
    "## CELLS\n",
    "# Create a worksheet for cell data\n",
    "worksheet_cell = workbook.add_worksheet('Cells')\n",
    "\n",
    "# HEADER\n",
    "# Write the header row for the 'Cells' worksheet\n",
    "worksheet_cell.write_row('A1:E1', ['#ID', 'X [um]', 'Y [um]', 'Area Nuclei [um2]'], header)\n",
    "\n",
    "# CONTENT\n",
    "# Write the data for each nucleus\n",
    "for row, value in enumerate(labels):\n",
    "    worksheet_cell.write(row + 1, 0, value)  # Write nucleus ID\n",
    "    worksheet_cell.write(row + 1, 1, barycenter_coords[value][0], floats)  # Write X coordinate\n",
    "    worksheet_cell.write(row + 1, 2, barycenter_coords[value][1], floats)  # Write Y coordinate\n",
    "    worksheet_cell.write(row + 1, 3, areas[value], floats)  # Write area of the nucleus\n",
    "    clear_output(wait=True)  # Clear the output to show progress\n",
    "    print('NUCLEI ' + str(row + 1) + ' / ' + str(len(labels + 1)))  # Print progress\n",
    "\n",
    "## ROI SHEET\n",
    "# Create a worksheet for ROI data\n",
    "worksheet_ROI = workbook.add_worksheet('ROI')\n",
    "\n",
    "# HEADER\n",
    "# Write the header row for the 'ROI' worksheet\n",
    "worksheet_ROI.write_row('A1:E1', ['# NUCLEI', 'TOT AREA [um2]', 'ROI AREA [um2]', 'CONC NUCLEI in ROI [cells/um2]'], header)\n",
    "\n",
    "# CONTENT\n",
    "# Write the ROI data\n",
    "worksheet_ROI.write(1, 0, len(labels + 1))  # Write the total number of nuclei\n",
    "worksheet_ROI.write(1, 1, fullA, exp)  # Write the total area of the image\n",
    "worksheet_ROI.write(1, 2, roiA, exp)  # Write the total area of the ROI\n",
    "worksheet_ROI.write(1, 3, roiCON, exp)  # Write the cell concentration in the ROI\n",
    "\n",
    "# Close the workbook to save the file\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c18e04-f518-4af6-b31b-9d670de8a79f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
