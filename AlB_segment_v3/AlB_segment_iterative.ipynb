{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a38257f-46bb-400f-96a7-9e4bda768d61",
   "metadata": {},
   "source": [
    "## PACK INSTALLATION (Restart kernel after run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ea9be9-7e17-4004-a41c-9133945aaf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the scikit-learn library for machine learning algorithms\n",
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6087dd87-8742-4e60-8f02-dea806bcdb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the xlsxwriter library for creating Excel files\n",
    "pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b970855-4941-4124-9a76-872a8c42ca87",
   "metadata": {},
   "source": [
    "## IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e1262a-3ccc-4c94-8f6e-8a5784ced14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OpenCV and check its version\n",
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61116848-a1b8-4dea-a7da-25a040cc7e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for image processing, visualization, and machine learning\n",
    "from PIL import Image\n",
    "\n",
    "# Napari for interactive visualization\n",
    "import napari\n",
    "\n",
    "# General-purpose libraries\n",
    "import scipy\n",
    "import csv\n",
    "import imghdr\n",
    "import colorsys\n",
    "import os\n",
    "import xlsxwriter\n",
    "\n",
    "# Numerical computations\n",
    "import numpy as np\n",
    "\n",
    "# OpenCV for image processing\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyVista for 3D visualization\n",
    "import pyvista as pv\n",
    "\n",
    "# Stardist for deep learning-based segmentation\n",
    "from csbdeep.utils import normalize\n",
    "from stardist.models import StarDist2D, Config3D, StarDist3D\n",
    "from stardist.data import test_image_nuclei_2d\n",
    "from stardist.plot import render_label\n",
    "\n",
    "# Scipy and Skimage for image processing and segmentation\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "from skimage import filters\n",
    "from skimage.draw import disk\n",
    "from skimage.segmentation import watershed\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.filters import threshold_local\n",
    "from scipy.ndimage import center_of_mass\n",
    "\n",
    "# from skimage.feature import peak_local_max\n",
    "from vispy.color import Colormap\n",
    "from IPython.display import display_html\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from stardist.models import StarDist2D, Config3D, StarDist3D\n",
    "from stardist.data import test_image_nuclei_2d\n",
    "from stardist.plot import render_label\n",
    "\n",
    "# Scikit-learn for machine learning algorithms\n",
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "# Morphological operations for image processing\n",
    "from skimage.morphology import remove_small_holes, remove_small_objects\n",
    "from skimage.morphology import closing, square\n",
    "\n",
    "# Napari settings for interactive visualization\n",
    "from napari.settings import get_settings\n",
    "settings = get_settings()\n",
    "\n",
    "# AICSImageIO for reading and writing image files\n",
    "from aicsimageio import AICSImage\n",
    "from tifffile import imwrite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17193b5-9fbb-41ca-85de-fb02a8f63bad",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91518aa-cda9-4b09-a916-a0fc5257e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the pixel coordinates that lie inside an ellipse\n",
    "def ellipse_pixels(imarray, center, semi_axes, rotation, image_shape):\n",
    "    \"\"\"\n",
    "    Generate the pixel coordinates that lie inside an ellipse.\n",
    "\n",
    "    Parameters:\n",
    "    - center: Tuple (x, y) representing the center of the ellipse.\n",
    "    - semi_axes: Tuple (semi_major_axis, semi_minor_axis) representing the lengths of the ellipse's axes.\n",
    "    - rotation: Rotation angle of the ellipse in radians.\n",
    "    - image_shape: Shape of the image (height, width) to constrain the ellipse.\n",
    "\n",
    "    Returns:\n",
    "    - A 2D array of pixel coordinates (row, column) that lie inside the ellipse.\n",
    "    \"\"\"\n",
    "    # Create a grid of x and y coordinates for the image\n",
    "    y, x = np.meshgrid(np.arange(imarray.shape[1]), np.arange(imarray.shape[0]), indexing='xy')\n",
    "    \n",
    "    # Compute the cosine and sine of the rotation angle\n",
    "    cos_theta = np.cos(rotation)\n",
    "    sin_theta = np.sin(rotation)\n",
    "    \n",
    "    # Rotate the x and y coordinates to align with the ellipse's axes\n",
    "    x_rot = cos_theta * (x - center[0]) + sin_theta * (y - center[1])\n",
    "    y_rot = -sin_theta * (x - center[0]) + cos_theta * (y - center[1])\n",
    "\n",
    "    # Create a mask for pixels that lie inside the ellipse\n",
    "    mask = (x_rot / semi_axes[0])**2 + (y_rot / semi_axes[1])**2 <= 1\n",
    "\n",
    "    # Enable interactive mode for Napari (if needed)\n",
    "    settings.application.ipy_interactive = True\n",
    "\n",
    "    # Return the coordinates of the pixels inside the ellipse\n",
    "    return np.column_stack(np.where(mask))\n",
    "\n",
    "# Function to convert an array of RGB values to HSV (Hue, Saturation, Value)\n",
    "def rgb_to_hsv(rgb_array):\n",
    "    \"\"\"\n",
    "    Convert an array of RGB values to HSV (Hue, Saturation, Value).\n",
    "\n",
    "    Parameters:\n",
    "    - rgb_array: A 2D array where each row is an RGB triplet (R, G, B).\n",
    "\n",
    "    Returns:\n",
    "    - A 2D array where each row is an HSV triplet (H, S, V).\n",
    "      H is in degrees (0-360), S and V are percentages (0-100).\n",
    "    \"\"\"\n",
    "    hsv_list = []\n",
    "    for rgb in rgb_array:\n",
    "        r, g, b = rgb  # Extract the RGB components\n",
    "        h, s, v = colorsys.rgb_to_hsv(r, g, b)  # Convert RGB to HSV\n",
    "        hsv_list.append([h * 360, s * 100, v * 100])  # Scale H to degrees, S and V to percentages\n",
    "    return np.array(hsv_list)\n",
    "\n",
    "# Function to read a CSV file and convert its contents into a matrix\n",
    "def csv_to_matrix(file_path):\n",
    "    \"\"\"\n",
    "    Read a CSV file and convert its contents into a matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "    - A 2D list where each row corresponds to a row in the CSV file.\n",
    "    \"\"\"\n",
    "    matrix = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            # Convert numeric values to integers, leave others as strings\n",
    "            matrix.append([int(value) if value.replace('.', '', 1).isdigit() else value for value in row])\n",
    "    return matrix\n",
    "\n",
    "# Function to classify test points based on their similarity to a cloud of points using Kernel Density Estimation (KDE)\n",
    "def classify_points(cloud_points, test_points, bandwidth=1.0):\n",
    "    \"\"\"\n",
    "    Classify test points based on their similarity to a cloud of points using Kernel Density Estimation (KDE).\n",
    "\n",
    "    Parameters:\n",
    "    - cloud_points: A 2D array of points representing the training data.\n",
    "    - test_points: A 2D array of points to classify.\n",
    "    - bandwidth: Bandwidth parameter for the KDE (controls smoothness).\n",
    "\n",
    "    Returns:\n",
    "    - A 1D array of probabilities for each test point.\n",
    "    \"\"\"\n",
    "    # Fit a Kernel Density Estimator to the cloud points\n",
    "    kde = KernelDensity(bandwidth=bandwidth, kernel='gaussian')\n",
    "    kde.fit(cloud_points)\n",
    "    \n",
    "    # Evaluate the probability density for each test point\n",
    "    log_density = kde.score_samples(test_points)\n",
    "    \n",
    "    # Convert log-density to probabilities\n",
    "    probabilities = np.exp(log_density)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e50e0a-b419-444a-b79a-823ffb3ff84c",
   "metadata": {},
   "source": [
    "## Training image\n",
    "\n",
    "Choose the image that will be used as training. It will be opened in Napari. Choose the circular selection on the right and choose as many nuclei as possible to train the algorithm. Then close the Napari window to continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8ac240-dfab-4d3b-ac62-b9ffe06f3d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training file and extract its name without the extension\n",
    "training_file = '10Xcow1_IL1_4_zoom.tif'\n",
    "training_stem = os.path.splitext(os.path.basename(training_file))[0]\n",
    "\n",
    "# Open the TIFF file as an image\n",
    "img_train = Image.open('./Training_files/' + training_file)\n",
    "\n",
    "# Convert the image to a NumPy array for further processing\n",
    "imarray_train = np.array(img_train)\n",
    "\n",
    "# Remove alpha channel if present\n",
    "if imarray_train.shape[2] == 4:\n",
    "    imarray_train = imarray_train[:, :, :3]\n",
    "\n",
    "# Create a copy of the original image to define the ROI (Region of Interest)\n",
    "ROI_train = imarray_train.copy()\n",
    "\n",
    "# Initialize a mask image with the same dimensions as the green channel of the original image\n",
    "mask_train = np.zeros(np.shape(imarray_train[:, :, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff68555e-12e0-4fc5-9dab-7562c53d25ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for the investigation\n",
    "step = 30  # Size of the square for investigation\n",
    "delta = 1  # Sensitivity for blue dominance\n",
    "holes_threshold = 1000  # Minimum area to consider a hole\n",
    "island_threshold = 1000  # Minimum size to consider an object\n",
    "\n",
    "# Flag to determine whether to use an existing CSV file for training points\n",
    "use_csv = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d8f95a-527f-47bf-87e6-ec5acb70b43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collect average brightness and contrast from ROI of training image\n",
    "\n",
    "# Iterate through the image in steps to identify blue-dominant regions\n",
    "for i in range(1 + step, imarray_train.shape[0], step):\n",
    "    for j in range(1 + step, imarray_train.shape[1], step):\n",
    "        # Check if the blue channel is dominant over both red and green channels\n",
    "        if (\n",
    "            np.mean(ROI_train[i-step:i+step, j-step:j+step, 2]) >= delta + np.mean(ROI_train[i-step:i+step, j-step:j+step, 1]) and\n",
    "            np.mean(ROI_train[i-step:i+step, j-step:j+step, 2]) >= delta + np.mean(ROI_train[i-step:i+step, j-step:j+step, 0])\n",
    "        ):\n",
    "            # Mark the region as part of the mask\n",
    "            mask_train[i:i+step, j:j+step, :] = 1\n",
    "        \n",
    "# Calculate average brightness for the whole image and ROI\n",
    "bright_train=np.mean(imarray_train[:,:,:])\n",
    "bright_train_ROI=np.mean(imarray_train[mask_train==1])\n",
    "\n",
    "# Calculate average brightness for each channel\n",
    "bright_train_R=np.mean(imarray_train[:,:,0])\n",
    "bright_train_G=np.mean(imarray_train[:,:,1])\n",
    "bright_train_B=np.mean(imarray_train[:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d06e633-02c6-43cb-818d-208e37369b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply constant brightness to the training image\n",
    "\n",
    "# Only apply if not using CSV or CSV does not exist\n",
    "if not(use_csv and os.path.exists('./Training_files/' + training_stem + '_yes_points.csv')):\n",
    "    for i in range(1, imarray_train.shape[0]-1, 1):\n",
    "        for j in range(1, imarray_train.shape[1]-1, 1):\n",
    "            step_x=5 \n",
    "            step_y=5\n",
    "            if mask_train[i,j,0]==1:\n",
    "                # Adjust step size at the borders\n",
    "                if i<step_x:\n",
    "                    step_x=i\n",
    "                elif i>(imarray_train.shape[0]-step_x):\n",
    "                    step_x=imarray_train.shape[0]-i\n",
    "                if j<step_y:\n",
    "                    step_y=j\n",
    "                elif j>(imarray_train.shape[1]-step_y):\n",
    "                    step_y=imarray_train.shape[1]-j\n",
    "    \n",
    "                # Calculate brightness in the region\n",
    "                bright_train_region=np.mean(imarray_train[i-step_x:i+step_x, j-step_y:j+step_y,:])\n",
    "    \n",
    "                # Adjust ROI brightness to match global brightness\n",
    "                for h in [0,1,2]:\n",
    "                    if (ROI_train[i,j,h]-int(bright_train_region-bright_train))<256:\n",
    "                        ROI_train[i,j,h]=ROI_train[i,j,h]-int(bright_train_region-bright_train)\n",
    "                    else:\n",
    "                        ROI_train[i,j,h]=255                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88135c2c-7c51-4cd6-a357-898cc079625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable interactive mode for Napari\n",
    "settings.application.ipy_interactive = True\n",
    "\n",
    "# Only show Napari viewer if not using CSV or CSV does not exist\n",
    "if not(use_csv and os.path.exists('./Training_files/' + training_stem + '_yes_points.csv')):\n",
    "    viewer_0 = napari.Viewer()\n",
    "    \n",
    "    # Add original image\n",
    "    viewer_0.add_image(imarray_train, name='Original', \n",
    "                    colormap='grey', blending='additive')\n",
    "    # Add mask image\n",
    "    viewer_0.add_image(mask_train, name='Violet', \n",
    "                    colormap='green', blending='additive')\n",
    "    # Add ROI image\n",
    "    viewer_0.add_image(ROI_train, name='ROI', \n",
    "                    colormap='grey', blending='additive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0eff87-5c1b-4e54-b111-fdd295ace5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the CSV file with training points exists\n",
    "if use_csv and os.path.exists('./Training_files/' + training_stem + '_yes_points.csv'):\n",
    "    # Load training points from the CSV file\n",
    "    yes_points = csv_to_matrix('./Training_files/' + training_stem + '_yes_points.csv')\n",
    "else:\n",
    "    # Initialize an empty list for training points\n",
    "    yes_points = []\n",
    "    \n",
    "    # Create an empty label array for the ROI\n",
    "    ROI_labels = np.zeros(imarray_train.shape)\n",
    "    \n",
    "    # Disable interactive mode for Napari\n",
    "    settings.application.ipy_interactive = False\n",
    "    \n",
    "    # Open the training image in Napari for manual annotation\n",
    "    viewer_c = napari.Viewer()\n",
    "    viewer_c.add_image(imarray_train, name='Original', \n",
    "                       colormap='grey', blending='additive')\n",
    "    \n",
    "    # Callback function to handle shape addition in Napari\n",
    "    def on_shape_added(layer, event):\n",
    "        shapes_layer = event.source\n",
    "\n",
    "    # Add a shapes layer for annotating nuclei\n",
    "    shapes_layer = viewer_c.add_shapes(shape_type=\"circle\", name=\"Nuclei training\")\n",
    "    \n",
    "    # Connect the mouse drag event to the callback function\n",
    "    viewer_c.mouse_drag_callbacks.append(on_shape_added)\n",
    "    \n",
    "    # Run Napari for manual annotation\n",
    "    napari.run()\n",
    "\n",
    "    # Process each annotated shape to extract training points\n",
    "    for s in range(0, np.shape(shapes_layer.data)[0]):\n",
    "        # Get the bounding box of the shape\n",
    "        xmax = np.max(shapes_layer.data[s][:, 0])\n",
    "        ymax = np.max(shapes_layer.data[s][:, 1])\n",
    "        xmin = np.min(shapes_layer.data[s][:, 0])\n",
    "        ymin = np.min(shapes_layer.data[s][:, 1])\n",
    "    \n",
    "        # Calculate ellipse parameters\n",
    "        center = ((xmax + xmin) / 2, (ymax + ymin) / 2)  # Center of the ellipse\n",
    "        semi_axes = (\n",
    "            abs(xmax - xmin) / 2,  # Semi-major axis (height / 2)\n",
    "            abs(ymax - ymin) / 2,  # Semi-minor axis (width / 2)\n",
    "        )\n",
    "        rotation = 0  # Napari's ellipses are axis-aligned by default\n",
    "    \n",
    "        # Get the shape of the training image\n",
    "        image_shape = imarray_train.shape\n",
    "    \n",
    "        # Get the pixel coordinates inside the ellipse\n",
    "        enclosed_pixels = ellipse_pixels(imarray_train, center, semi_axes, rotation, image_shape[:2])\n",
    "\n",
    "        # If the CSV file exists, load the existing training points\n",
    "        if os.path.exists('./Training_files/' + training_stem + '_yes_points.csv'):\n",
    "            yes_points = csv_to_matrix('./Training_files/' + training_stem + '_yes_points.csv')\n",
    "    \n",
    "        # Add the RGB values of the enclosed pixels to the training points\n",
    "        for i in range(enclosed_pixels.shape[0]):\n",
    "            x = enclosed_pixels[i][0]\n",
    "            y = enclosed_pixels[i][1]\n",
    "            yes_points.append([ROI_train[x, y, 0], ROI_train[x, y, 1], ROI_train[x, y, 2]])\n",
    "\n",
    "        # Save the updated training points to the CSV file\n",
    "        with open('./Training_files/' + training_stem + '_yes_points.csv', 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerows(yes_points)\n",
    "\n",
    "# Convert the training points to a NumPy array for further processing\n",
    "yes_points = np.array(yes_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c31b259-215a-4842-b660-2cb13e973247",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize distribution of training points\n",
    "\n",
    "# Plot RGB scatter plots for the training points\n",
    "fig, axs = plt.subplots(1,3,figsize=(15,5))\n",
    "axs[0].scatter(yes_points[:,0],yes_points[:,1], c = yes_points/255)\n",
    "axs[0].set_xlim((0,256))\n",
    "axs[0].set_xlabel(\"RED\")\n",
    "axs[0].set_ylim((0,256))\n",
    "axs[0].set_ylabel(\"GREEN\")\n",
    "axs[1].scatter(yes_points[:,0],yes_points[:,2], c = yes_points/255)\n",
    "axs[1].set_xlim((0,256))\n",
    "axs[1].set_xlabel(\"RED\")\n",
    "axs[1].set_ylim((0,256))\n",
    "axs[1].set_ylabel(\"BLUE\")\n",
    "axs[2].scatter(yes_points[:,1],yes_points[:,2], c = yes_points/255)\n",
    "axs[2].set_xlim((0,256))\n",
    "axs[2].set_xlabel(\"GREEN\")\n",
    "axs[2].set_ylim((0,256))\n",
    "axs[2].set_ylabel(\"BLUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b636608-7690-4b38-b605-b238bc41ddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize distribution of training points in HSV color space\n",
    "yes_points_hsv=rgb_to_hsv(yes_points)\n",
    "\n",
    "# Plot HSV scatter plots for the training points\n",
    "fig, axs = plt.subplots(1,3,figsize=(15,5))\n",
    "axs[0].scatter(yes_points_hsv[:,0],yes_points_hsv[:,1]/100.0, c = yes_points/255)\n",
    "axs[0].set_xlim((0,360))\n",
    "axs[0].set_xlabel(\"H\")\n",
    "#axs[0].set_ylim((0,100))\n",
    "axs[0].set_ylabel(\"S\")\n",
    "axs[1].scatter(yes_points_hsv[:,0],yes_points_hsv[:,2]/100.0, c = yes_points/255)\n",
    "axs[1].set_xlim((0,360))\n",
    "axs[1].set_xlabel(\"H\")\n",
    "#axs[1].set_ylim((0,100))\n",
    "axs[1].set_ylabel(\"V\")\n",
    "axs[2].scatter(yes_points_hsv[:,1]/100.0,yes_points_hsv[:,2]/100.0, c = yes_points/255)\n",
    "#axs[2].set_xlim((0,100))\n",
    "axs[2].set_xlabel(\"S\")\n",
    "#axs[2].set_ylim((0,100))\n",
    "axs[2].set_ylabel(\"V\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9de469-3afa-4dde-a459-45a9fb67a321",
   "metadata": {},
   "source": [
    "## File upload\n",
    "Takes all the images inside \"Input_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41837bd-55ba-4b37-affd-bc756542813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all files in the 'Input_images' directory\n",
    "files = os.listdir('Input_images')\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for num, tiff_file in enumerate(files):\n",
    "    # Process only TIFF files\n",
    "    if tiff_file.endswith(\".tif\") or tiff_file.endswith(\".tiff\"):\n",
    "        print(tiff_file)  # Print the name of the file being processed\n",
    "\n",
    "        # Run the segmentation notebook for the current file\n",
    "        %run ./Notebook_calls/AlB_segment_call.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
