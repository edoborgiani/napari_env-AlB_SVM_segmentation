{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2e1262a-3ccc-4c94-8f6e-8a5784ced14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.5.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61116848-a1b8-4dea-a7da-25a040cc7e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 12:55:46.385624: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-17 12:55:46.386261: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-17 12:55:46.389761: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-17 12:55:46.428853: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-17 12:55:47.193912: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import napari\n",
    "import scipy\n",
    "import xlsxwriter\n",
    "import imghdr\n",
    "import colorsys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyvista as pv\n",
    "\n",
    "from csbdeep.utils import normalize\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "from skimage import filters\n",
    "from skimage.draw import disk\n",
    "# from skimage.segmentation import watershed\n",
    "# from skimage.feature import peak_local_max\n",
    "from vispy.color import Colormap\n",
    "from IPython.display import display_html\n",
    "\n",
    "from stardist.models import StarDist2D, Config3D, StarDist3D\n",
    "from stardist.data import test_image_nuclei_2d\n",
    "from stardist.plot import render_label\n",
    "\n",
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "from napari.settings import get_settings\n",
    "settings = get_settings()\n",
    "\n",
    "from aicsimageio import AICSImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49eb3381-a03c-4ce8-b871-784e5113fdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ellipse_pixels(center, semi_axes, rotation, image_shape):\n",
    "    y, x = np.meshgrid(np.arange(imarray.shape[1]), np.arange(imarray.shape[0]), indexing='xy')\n",
    "    cos_theta = np.cos(rotation)\n",
    "    sin_theta = np.sin(rotation)\n",
    "\n",
    "    # Transform pixel coordinates to ellipse coordinates\n",
    "    x_rot = cos_theta * (x - center[0]) + sin_theta * (y - center[1])\n",
    "    y_rot = -sin_theta * (x - center[0]) + cos_theta * (y - center[1])\n",
    "\n",
    "    # Ellipse equation: (x_rot / a)^2 + (y_rot / b)^2 <= 1\n",
    "    mask = (x_rot / semi_axes[0])**2 + (y_rot / semi_axes[1])**2 <= 1\n",
    "\n",
    "    settings.application.ipy_interactive = True\n",
    "\n",
    "    # viewer_c = napari.Viewer()\n",
    "\n",
    "    # viewer_c.add_image(y, name='Original', \n",
    "    #             colormap='grey', blending='additive')\n",
    "\n",
    "    # Get pixel coordinates inside the ellipse\n",
    "    return np.column_stack(np.where(mask))\n",
    "\n",
    "def rgb_to_hsv(rgb_array):\n",
    "    hsv_list = []\n",
    "    for rgb in rgb_array:\n",
    "        r, g, b = rgb  # Extract the components\n",
    "        h, s, v = colorsys.rgb_to_hsv(r, g, b)  # Convert to HSV\n",
    "        hsv_list.append([h * 360, s * 100, v * 100])  # Scale H to degrees, S and V to percentages\n",
    "    return np.array(hsv_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9de469-3afa-4dde-a459-45a9fb67a321",
   "metadata": {},
   "source": [
    "## File upload\n",
    "Write the name of the file that needs to be investigated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c41837bd-55ba-4b37-affd-bc756542813c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3056, 2920, 3)\n"
     ]
    }
   ],
   "source": [
    "tiff_file='cow1_d0_1_1.tif'\n",
    "\n",
    "img=Image.open(tiff_file)\n",
    "imarray=np.array(img)\n",
    "print(imarray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ebff832-baa6-468b-8548-8803158d5b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_X=1.0\n",
    "r_Y=1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457a965b-6f9b-40dd-ae6f-4a8bbcedd6a4",
   "metadata": {},
   "source": [
    "## ROI \n",
    "This section will find the region of interest by checking the blue part. Variables: [step] will dictate the size of the square of investigation (smaller values will get a better resolution but r "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b68c90f-af3e-4417-acf3-13d1943683ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_image=imarray.copy()\n",
    "mask_image=np.zeros(np.shape(imarray[:,:,1]))\n",
    "step=5\n",
    "\n",
    "for i in range(1+step,imarray.shape[0],step):\n",
    "    for j in range(1+step,imarray.shape[1],step):\n",
    "        #print(j)\n",
    "        if(np.mean(ROI_image[i-step:i+step,j-step:j+step,2])<3+np.mean(ROI_image[i-step:i+step,j-step:j+step,1])):\n",
    "            ROI_image[i:i+step,j:j+step]=0\n",
    "        else:\n",
    "            mask_image[i:i+step,j:j+step]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cc4a9b-31ff-428f-aa0e-a5a55d4d7127",
   "metadata": {},
   "source": [
    "### Training image\n",
    "Choose the image that will be used as training. It will be opened in Napari. Choose the circular selection on the right and choose as many nuclei as possible to train the algorithm. Then close the Napari window to continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b74fe56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libGL error: glx: failed to create dri3 screen\n",
      "libGL error: failed to load driver: nouveau\n"
     ]
    }
   ],
   "source": [
    "tiff_file='cow1_cont1a.tif'\n",
    "image=Image.open(tiff_file)\n",
    "imarray=np.array(image)\n",
    "\n",
    "yes_points=[]\n",
    "\n",
    "ROI_labels=np.zeros(imarray.shape)\n",
    "\n",
    "settings.application.ipy_interactive = False\n",
    "\n",
    "viewer_c = napari.Viewer()\n",
    "\n",
    "viewer_c.add_image(imarray, name='Original', \n",
    "            colormap='grey', blending='additive')\n",
    "\n",
    "def on_shape_added(layer, event):\n",
    "    shapes_layer= event.source\n",
    "\n",
    "shapes_layer = viewer_c.add_shapes(shape_type=\"circle\", name=\"Nuclei training\")\n",
    "\n",
    "# Connect the click event to our callback function\n",
    "viewer_c.mouse_drag_callbacks.append(on_shape_added)\n",
    "\n",
    "napari.run()\n",
    "\n",
    "for s in range(0,np.shape(shapes_layer.data)[0]):\n",
    "    xmax=np.max(shapes_layer.data[s][:,0])\n",
    "    ymax=np.max(shapes_layer.data[s][:,1])\n",
    "    xmin=np.min(shapes_layer.data[s][:,0])\n",
    "    ymin=np.min(shapes_layer.data[s][:,1])\n",
    "    #print(shapes_layer.data)\n",
    "\n",
    "    # Calculate ellipse parameters\n",
    "    center = ((xmax + xmin) / 2, (ymax + ymin) / 2)\n",
    "    semi_axes = (\n",
    "        abs(xmax - xmin) / 2,  # Semi-major axis (height / 2)\n",
    "        abs(ymax - ymin) / 2,  # Semi-minor axis (width / 2)\n",
    "    )\n",
    "    rotation = 0  # Napari's ellipses are axis-aligned by default\n",
    "\n",
    "    image_shape=imarray.shape\n",
    "    #print(center)\n",
    "    #print(semi_axes)\n",
    "    #print(image_shape)\n",
    "\n",
    "    # Get the pixel coordinates inside the ellipse\n",
    "    enclosed_pixels = ellipse_pixels(center, semi_axes, rotation, image_shape[:2])\n",
    "\n",
    "    #print(enclosed_pixels)\n",
    "\n",
    "    for i in range(enclosed_pixels.shape[0]):\n",
    "        x=enclosed_pixels[i][0]\n",
    "        y=enclosed_pixels[i][1]\n",
    "        #print(new_point)\n",
    "        yes_points.append([imarray[x,y,0],imarray[x,y,1],imarray[x,y,2]])\n",
    "\n",
    "yes_points=np.array(yes_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29edae86-68b0-4f8a-896e-c99018aaad60",
   "metadata": {},
   "source": [
    "After you run the next section, a new Napari window will appear with highlighted in green all the nuclei in the ROI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bcd6cc-8d5b-40be-b031-676606905327",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings.application.ipy_interactive = True\n",
    "\n",
    "imarray0=ROI_image.copy()\n",
    "\n",
    "imR=imarray0[:,:,0]\n",
    "imG=imarray0[:,:,1]\n",
    "imB=imarray0[:,:,2]\n",
    "\n",
    "yes_points_hsv=rgb_to_hsv(yes_points)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "yes_points_scaled = scaler.fit_transform(yes_points_hsv)\n",
    "\n",
    "# Train a one-class SVM\n",
    "# `nu` controls the sensitivity (fraction of outliers allowed)\n",
    "sensitivity = 0.1  # Choose sensitivity level (e.g., 10% of points allowed as outliers)\n",
    "clf = OneClassSVM(kernel='rbf', nu=sensitivity, gamma=0.1) #'scale')\n",
    "clf.fit(yes_points_scaled)\n",
    "\n",
    "# Train SVM with polynomial kernel\n",
    "# clf = SVC(kernel='poly', degree=5, C=1)\n",
    "# clf.fit(X_scaled, y)\n",
    "\n",
    "imV=np.zeros(np.shape(imR))\n",
    "for i in range(step,np.shape(imV)[0]):\n",
    "    for j in range(step,np.shape(imV)[1]):\n",
    "        #print(pR)\n",
    "        if (mask_image[i,j]>0):\n",
    "            pR=imR[i,j]\n",
    "            pG=imG[i,j]\n",
    "            pB=imB[i,j]\n",
    "            X = np.array([\n",
    "                [pR, pG, pB]\n",
    "            ])\n",
    "            #print(X)\n",
    "            X_hsv = rgb_to_hsv(X)\n",
    "            X_scaled = scaler.transform(X_hsv)\n",
    "            #print(X_scaled)\n",
    "            predictions = clf.predict(X_scaled)\n",
    "            #print(predictions)\n",
    "            if predictions>0:\n",
    "                imV[i,j]=1\n",
    "                #yes_points=np.append(yes_points,X,axis=0)\n",
    "            else:\n",
    "                imV[i,j]=0\n",
    "                #no_points=np.append(no_points,X,axis=0)\n",
    "        else:\n",
    "            j+=step\n",
    "\n",
    "viewer_0 = napari.Viewer()\n",
    "\n",
    "viewer_0.add_image(imarray0, name='Original', \n",
    "                colormap='grey', blending='additive')\n",
    "viewer_0.add_image(imV, name='Violet', \n",
    "                colormap='green', blending='additive')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
