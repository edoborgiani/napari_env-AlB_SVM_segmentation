{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cad7ff8-ccf0-489e-ab8c-8456f6a47914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ellipse_pixels(center, semi_axes, rotation, image_shape):\n",
    "    y, x = np.meshgrid(np.arange(imarray.shape[1]), np.arange(imarray.shape[0]), indexing='xy')\n",
    "    cos_theta = np.cos(rotation)\n",
    "    sin_theta = np.sin(rotation)\n",
    "    \n",
    "    x_rot = cos_theta * (x - center[0]) + sin_theta * (y - center[1])\n",
    "    y_rot = -sin_theta * (x - center[0]) + cos_theta * (y - center[1])\n",
    "\n",
    "    mask = (x_rot / semi_axes[0])**2 + (y_rot / semi_axes[1])**2 <= 1\n",
    "\n",
    "    settings.application.ipy_interactive = True\n",
    "\n",
    "    return np.column_stack(np.where(mask))\n",
    "\n",
    "def rgb_to_hsv(rgb_array):\n",
    "    hsv_list = []\n",
    "    for rgb in rgb_array:\n",
    "        r, g, b = rgb  # Extract the components\n",
    "        h, s, v = colorsys.rgb_to_hsv(r, g, b)  # Convert to HSV\n",
    "        hsv_list.append([h * 360, s * 100, v * 100])  # Scale H to degrees, S and V to percentages\n",
    "    return np.array(hsv_list)\n",
    "\n",
    "def csv_to_matrix(file_path):\n",
    "    matrix = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            matrix.append([int(value) if value.replace('.', '', 1).isdigit() else value for value in row])\n",
    "    return matrix\n",
    "\n",
    "def classify_points(cloud_points, test_points, bandwidth=1.0):\n",
    "    # Fit a Kernel Density Estimator to the cloud points\n",
    "    kde = KernelDensity(bandwidth=bandwidth, kernel='gaussian')\n",
    "    kde.fit(cloud_points)\n",
    "    \n",
    "    # Evaluate the probability density for each test point\n",
    "    log_density = kde.score_samples(test_points)\n",
    "    \n",
    "    # Convert log-density to probabilities\n",
    "    probabilities = np.exp(log_density)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9de469-3afa-4dde-a459-45a9fb67a321",
   "metadata": {},
   "source": [
    "## File upload\n",
    "Write the name of the file that needs to be investigated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41837bd-55ba-4b37-affd-bc756542813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_stem=os.path.splitext(os.path.basename(tiff_file))[0]\n",
    "\n",
    "img=Image.open('./Input_images/' + tiff_file)\n",
    "imarray=np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebff832-baa6-468b-8548-8803158d5b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_X=0.698 #um, 10X\n",
    "r_Y=0.698 #um, 10X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457a965b-6f9b-40dd-ae6f-4a8bbcedd6a4",
   "metadata": {},
   "source": [
    "## ROI \n",
    "This section will find the region of interest by checking the blue part. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c9524e-d16c-46ab-a027-5c23c99644cf",
   "metadata": {},
   "source": [
    "#### If the image is RGBA and we only want RGB, remove A channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01697f9d-029d-4a87-9323-c8df04bd58f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove alpha channel if present\n",
    "if imarray.shape[2] == 4:\n",
    "    imarray = imarray[:, :, :3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d835546a-c8d8-478e-ad3e-c4228fa84c9f",
   "metadata": {},
   "source": [
    "Variables: [step] will dictate the size of the square of investigation (smaller values will get a better resolution but slower run), [delta] will dictate the sensitivity of the blue level (smaller values lead to more false positive but higher values lead to more false negative).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b68c90f-af3e-4417-acf3-13d1943683ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_image = imarray.copy()\n",
    "\n",
    "mask_image = np.zeros(np.shape(imarray[:, :, 1]))\n",
    "step = 30\n",
    "delta = 1\n",
    "holes_threshold = 1000\n",
    "island_threshold = 1000\n",
    "\n",
    "for i in range(1 + step, imarray.shape[0], step):\n",
    "    for j in range(1 + step, imarray.shape[1], step):\n",
    "        # Ensure blue is dominant over both red and green\n",
    "        if (\n",
    "            np.mean(ROI_image[i-step:i+step, j-step:j+step, 2]) >= delta + np.mean(ROI_image[i-step:i+step, j-step:j+step, 1]) and\n",
    "            np.mean(ROI_image[i-step:i+step, j-step:j+step, 2]) >= delta + np.mean(ROI_image[i-step:i+step, j-step:j+step, 0])\n",
    "        ):\n",
    "            mask_image[i:i+step, j:j+step] = 1\n",
    "\n",
    "mask_filled = remove_small_holes(mask_image.astype(int), area_threshold=holes_threshold, connectivity=1)\n",
    "mask_filled = remove_small_objects(mask_filled, min_size=island_threshold, connectivity=1)\n",
    "\n",
    "ROI_image = imarray * np.stack([mask_filled] * 3, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cc4a9b-31ff-428f-aa0e-a5a55d4d7127",
   "metadata": {},
   "source": [
    "### Training image\n",
    "Choose the image that will be used as training. It will be opened in Napari. Choose the circular selection on the right and choose as many nuclei as possible to train the algorithm. Then close the Napari window to continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4284c32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_file='10Xcow1_IL1_4_zoom.tif'\n",
    "training_stem=os.path.splitext(os.path.basename(training_file))[0]\n",
    "\n",
    "training_img=Image.open('./Input_images/' + training_file)\n",
    "trainarray=np.array(training_img)\n",
    "\n",
    "#use_csv=True\n",
    "\n",
    "if use_csv and os.path.exists('./Training_files/' + training_stem+'_yes_points.csv'):\n",
    "    yes_points = csv_to_matrix('./Training_files/' + training_stem+'_yes_points.csv')\n",
    "else:\n",
    "    yes_points=[]\n",
    "    \n",
    "    ROI_labels=np.zeros(trainarray.shape)\n",
    "    \n",
    "    settings.application.ipy_interactive = False\n",
    "    \n",
    "    viewer_c = napari.Viewer()\n",
    "    \n",
    "    viewer_c.add_image(trainarray, name='Original', \n",
    "                colormap='grey', blending='additive')\n",
    "    \n",
    "    def on_shape_added(layer, event):\n",
    "        shapes_layer= event.source\n",
    "    \n",
    "    shapes_layer = viewer_c.add_shapes(shape_type=\"circle\", name=\"Nuclei training\")\n",
    "    \n",
    "    # Connect the click event to our callback function\n",
    "    viewer_c.mouse_drag_callbacks.append(on_shape_added)\n",
    "    \n",
    "    napari.run()\n",
    "\n",
    "    for s in range(0,np.shape(shapes_layer.data)[0]):\n",
    "        xmax=np.max(shapes_layer.data[s][:,0])\n",
    "        ymax=np.max(shapes_layer.data[s][:,1])\n",
    "        xmin=np.min(shapes_layer.data[s][:,0])\n",
    "        ymin=np.min(shapes_layer.data[s][:,1])\n",
    "        #print(shapes_layer.data)\n",
    "    \n",
    "        # Calculate ellipse parameters\n",
    "        center = ((xmax + xmin) / 2, (ymax + ymin) / 2)\n",
    "        semi_axes = (\n",
    "            abs(xmax - xmin) / 2,  # Semi-major axis (height / 2)\n",
    "            abs(ymax - ymin) / 2,  # Semi-minor axis (width / 2)\n",
    "        )\n",
    "        rotation = 0  # Napari's ellipses are axis-aligned by default\n",
    "    \n",
    "        image_shape=trainarray.shape\n",
    "    \n",
    "        # Get the pixel coordinates inside the ellipse\n",
    "        enclosed_pixels = ellipse_pixels(center, semi_axes, rotation, image_shape[:2])\n",
    "    \n",
    "        #print(enclosed_pixels)\n",
    "\n",
    "        if os.path.exists('./Training_files/' + training_stem+'_yes_points.csv'):\n",
    "            yes_points = csv_to_matrix('./Training_files/' + training_stem+'_yes_points.csv')\n",
    "    \n",
    "        for i in range(enclosed_pixels.shape[0]):\n",
    "            x=enclosed_pixels[i][0]\n",
    "            y=enclosed_pixels[i][1]\n",
    "            #print(new_point)\n",
    "            yes_points.append([trainarray[x,y,0],trainarray[x,y,1],trainarray[x,y,2]])\n",
    "\n",
    "        with open('./Training_files/' + training_stem+'_yes_points.csv', 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerows(yes_points)\n",
    "\n",
    "yes_points=np.array(yes_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29edae86-68b0-4f8a-896e-c99018aaad60",
   "metadata": {},
   "source": [
    "After you run the next section, a new Napari window will appear with highlighted in green all the nuclei in the ROI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e118b5-582a-4abc-8ffc-75c9140e1bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings.application.ipy_interactive = True\n",
    "\n",
    "imarray0=ROI_image.copy()\n",
    "\n",
    "imR=imarray0[:,:,0]\n",
    "imG=imarray0[:,:,1]\n",
    "imB=imarray0[:,:,2]\n",
    "\n",
    "yes_points_hsv=rgb_to_hsv(yes_points)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "yes_points_scaled = scaler.fit_transform(yes_points_hsv)\n",
    "\n",
    "sensitivity = 0.7  # Choose sensitivity level (e.g., 10% of points allowed as outliers)\n",
    "clf = OneClassSVM(kernel='rbf', nu=sensitivity, gamma='scale')\n",
    "clf.fit(yes_points_scaled)\n",
    "\n",
    "imV=np.zeros(np.shape(imR))\n",
    "tval=0\n",
    "for i in range(step,np.shape(imV)[0]):\n",
    "    for j in range(step,np.shape(imV)[1]):\n",
    "        tval+=1\n",
    "        #print(pR)\n",
    "        if (mask_filled[i,j]>0):\n",
    "            pR=imR[i,j]\n",
    "            pG=imG[i,j]\n",
    "            pB=imB[i,j]\n",
    "            X = np.array([\n",
    "                [pR, pG, pB]\n",
    "            ])\n",
    "            #print(X)\n",
    "            X_hsv = rgb_to_hsv(X)\n",
    "            X_scaled = scaler.transform(X_hsv)\n",
    "            #print(X_scaled)\n",
    "            predictions = classify_points(yes_points, X, bandwidth=20.0)\n",
    "            #print(predictions)\n",
    "            if predictions>0.0:\n",
    "                imV[i,j]=predictions[0]\n",
    "                #yes_points=np.append(yes_points,X,axis=0)\n",
    "            else:\n",
    "                imV[i,j]=0\n",
    "                #no_points=np.append(no_points,X,axis=0)\n",
    "        else:\n",
    "            j+=step\n",
    "\n",
    "        if (100.0*tval/(np.shape(imV)[0]*np.shape(imV)[1])%1.0==0.0):\n",
    "            clear_output(wait=True)\n",
    "            print('PROGRESS ' + str(100.0*tval/(np.shape(imV)[0]*np.shape(imV)[1])) + ' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c20e504-9bab-44ee-b218-15966098e140",
   "metadata": {},
   "source": [
    "#### Remove noise and big regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd08217c-5211-4cc2-bcd4-8a72a4c9a8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ðŸ”¹ Step 1: Thresholding: switch from grayscale to binary scale (different brightness to either 0 for background or 1 for nuclei)\n",
    "\n",
    "# Get all nonzero values in imV (ignoring background)\n",
    "valid_pixels = imV[imV > 0]  \n",
    "\n",
    "# Compute the 98th percentile threshold only for these valid pixels\n",
    "if len(valid_pixels) > 0:  # Ensure there are nonzero pixels\n",
    "    threshold_value = np.percentile(valid_pixels, 99.5)  \n",
    "    binary_mask = (imV >= threshold_value)  # Keep only the top 2% brightest pixels\n",
    "else:\n",
    "    binary_mask = np.zeros_like(imV)  # If no valid pixels, return empty mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a404a4-f02e-424c-b099-99d9c167f884",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ðŸ”¹ Step 2: Remove Noise & Artifacts below a specific pexil size \"min_size\"\n",
    "\n",
    "# Step 2: Remove Noise & Artifacts\n",
    "binary_mask2 = remove_small_objects(binary_mask, min_size=5)  \n",
    "binary_mask2 = closing(binary_mask2, square(3))  # Fills small holes and connects nearby white regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328d2ca1-f820-4b8a-a067-4fdd6bb84f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ðŸ”¹ Step 3: Remove Artifacts Based on Size (small and big)\n",
    "\n",
    "# Step 3: Remove Artifacts Based on Size\n",
    "min_nucleus_size = 1  \n",
    "max_nucleus_size = 130  \n",
    "filtered_mask = np.zeros_like(binary_mask2)\n",
    "\n",
    "for region in regionprops(label(binary_mask2)):\n",
    "    if min_nucleus_size <= region.area <= max_nucleus_size:\n",
    "        filtered_mask[label(binary_mask2) == region.label] = 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2576442-5e0b-4660-bbaa-f266ccb8e6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ðŸ”¹ Step 4: Watershed Segmentation\n",
    "\n",
    "# Step 4: Watershed for Better Separation\n",
    "distance = distance_transform_edt(filtered_mask)  \n",
    "markers = label(distance > 0.0001 * distance.max())  \n",
    "segmented_nuclei = watershed(-distance, markers, mask=filtered_mask)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34dc49c-6840-47e7-b872-7a95cfd12ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ðŸ”¹ Step 5: Filter by Roundness (Elongation Ratio)\n",
    "\n",
    "max_ratio = 3.0  # Maximum allowed elongation ratio (major_axis / minor_axis)\n",
    "filtered_segments = np.zeros_like(segmented_nuclei)  # Empty mask for valid segments\n",
    "\n",
    "k=1\n",
    "for region in regionprops(segmented_nuclei):\n",
    "    if region.minor_axis_length > 0:  # Avoid division by zero\n",
    "        elongation_ratio = region.major_axis_length / region.minor_axis_length  \n",
    "        if elongation_ratio <= max_ratio:  # Keep only segments with acceptable roundness\n",
    "            filtered_segments[segmented_nuclei == region.label] = k\n",
    "            k+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0583a406-631b-4df5-a014-7654aab4ef09",
   "metadata": {},
   "source": [
    "### Output \n",
    "Creates a .tiff file with multiple pages. P1 is the original image, P2 is the ROI chosen as the tissue, P3 is the detected nuclei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53d4253-87d2-4242-b275-de897e0613c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert images to RGB\n",
    "rgb_im = Image.fromarray(imarray.astype(np.uint8), mode=\"RGB\")\n",
    "rgb0_im = Image.fromarray(imarray0.astype(np.uint8), mode=\"RGB\")\n",
    "\n",
    "#filtered_segments = filtered_segments.astype(np.uint8)  # Ensure uint8 format\n",
    "filtered_segments_rgb=np.zeros((np.shape(filtered_segments)[0],np.shape(filtered_segments)[1],3))\n",
    "\n",
    "cmd=np.random.rand(np.max(filtered_segments)+1,3)\n",
    "cmd[0,:]=[0.0,0.0,0.0]\n",
    "\n",
    "#filtered_segments_normalized = filtered_segments / filtered_segments.max()  # Normalize\n",
    "for i in range(1,np.shape(filtered_segments)[0]):\n",
    "    for j in range(1,np.shape(filtered_segments)[1]):\n",
    "        filtered_segments_rgb[i,j,0] = int(cmd[filtered_segments[i,j],0] * 255.0)\n",
    "        filtered_segments_rgb[i,j,1] = int(cmd[filtered_segments[i,j],1] * 255.0)\n",
    "        filtered_segments_rgb[i,j,2] = int(cmd[filtered_segments[i,j],2] * 255.0)\n",
    "# Set background pixels (where filtered_segments is 0) to white\n",
    "#filtered_segments_rgb[filtered_segments == 0] = [255, 255, 255]\n",
    "\n",
    "filtered_segments_rgb=filtered_segments_rgb.astype('uint8')\n",
    "\n",
    "b_im = Image.fromarray(filtered_segments_rgb, mode=\"RGB\") \n",
    "\n",
    "\n",
    "# Save both images in a single TIFF file\n",
    "output_path = \"./Output_files/\"+tiff_stem+\"_output.tiff\"\n",
    "rgb_im.save(output_path, save_all=True, append_images=[rgb0_im,b_im])\n",
    "\n",
    "print(f\"TIFF file saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8791ded5-6ba5-4926-a633-a830f6879410",
   "metadata": {},
   "source": [
    "### QUANTIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0c9eeb-cf73-48ff-b210-566762a7dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.ndimage import label, center_of_mass\n",
    "\n",
    "labels = np.unique(filtered_segments)\n",
    "labels = labels[labels != 0]\n",
    "\n",
    "print('TOTAL NUCLEI ' + str(len(labels+1)))\n",
    "\n",
    "# Compute centroids\n",
    "barycenters = {labell: center_of_mass(filtered_segments == labell) for labell in labels}\n",
    "areas={labell: np.sum(filtered_segments == labell)*r_X*r_Y for labell in labels}\n",
    "\n",
    "# Convert to list of coordinates\n",
    "barycenter_coords = {k: (round(v[0], 2)*r_X, round(v[1], 2)*r_Y) for k, v in barycenters.items()}\n",
    "\n",
    "#Total Area ROI\n",
    "fullA=np.prod(np.shape(mask_image))*r_X*r_Y\n",
    "roiA=np.sum(mask_image)*r_X*r_Y\n",
    "\n",
    "#Concentration cells in ROI\n",
    "roiCON=(len(labels+1))/roiA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6d8187-8d56-4473-b7ef-1c98ca4c715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook=xlsxwriter.Workbook('./Output_files/'+ tiff_stem+'.xlsx')\n",
    "\n",
    "## FORMATS\n",
    "header=workbook.add_format({'bold':True})\n",
    "header.set_bg_color('yellow')\n",
    "floats=workbook.add_format({'num_format':'0.00'})\n",
    "exp=workbook.add_format()\n",
    "exp.set_num_format(11)\n",
    "\n",
    "## CELLS\n",
    "worksheet_cell=workbook.add_worksheet('Cells')\n",
    "\n",
    "#HEADER\n",
    "worksheet_cell.write_row('A1:E1',['#ID','X [um]','Y [um]','Area Nuclei [um2]'],header)\n",
    "    \n",
    "#CONTENT\n",
    "for row,value in enumerate(labels):\n",
    "    worksheet_cell.write(row+1,0,value)\n",
    "    worksheet_cell.write(row+1,1,barycenter_coords[value][0],floats)\n",
    "    worksheet_cell.write(row+1,2,barycenter_coords[value][1],floats)\n",
    "    worksheet_cell.write(row+1,3,areas[value],floats)\n",
    "    clear_output(wait=True)\n",
    "    print('NUCLEI ' + str(row+1) + ' / ' + str(len(labels+1)))\n",
    "\n",
    "## ROI SHEET\n",
    "worksheet_ROI=workbook.add_worksheet('ROI')\n",
    "\n",
    "#HEADER\n",
    "worksheet_ROI.write_row('A1:E1',['# NUCLEI','TOT AREA [um2]','ROI AREA [um2]','CONC NUCLEI in ROI [cells/um2]'],header)\n",
    "    \n",
    "#CONTENT\n",
    "\n",
    "worksheet_ROI.write(1,0,len(labels+1))\n",
    "worksheet_ROI.write(1,1,fullA,exp)\n",
    "worksheet_ROI.write(1,2,roiA,exp)\n",
    "worksheet_ROI.write(1,3,roiCON,exp)\n",
    "\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c18e04-f518-4af6-b31b-9d670de8a79f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
