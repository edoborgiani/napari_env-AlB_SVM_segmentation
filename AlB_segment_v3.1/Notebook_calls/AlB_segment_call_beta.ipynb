{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3921d7e7-a91f-4811-9909-c5dfa606f765",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from skimage.measure import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cad7ff8-ccf0-489e-ab8c-8456f6a47914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ellipse_pixels(imarray, center, semi_axes, rotation, image_shape):\n",
    "    \"\"\"\n",
    "    Generate the pixel coordinates that lie inside an ellipse.\n",
    "\n",
    "    Parameters:\n",
    "    - center: Tuple (x, y) representing the center of the ellipse.\n",
    "    - semi_axes: Tuple (semi_major_axis, semi_minor_axis) representing the lengths of the ellipse's axes.\n",
    "    - rotation: Rotation angle of the ellipse in radians.\n",
    "    - image_shape: Shape of the image (height, width) to constrain the ellipse.\n",
    "\n",
    "    Returns:\n",
    "    - A 2D array of pixel coordinates (row, column) that lie inside the ellipse.\n",
    "    \"\"\"\n",
    "    # Create a grid of x and y coordinates for the image\n",
    "    y, x = np.meshgrid(np.arange(imarray.shape[1]), np.arange(imarray.shape[0]), indexing='xy')\n",
    "    \n",
    "    # Compute the cosine and sine of the rotation angle\n",
    "    cos_theta = np.cos(rotation)\n",
    "    sin_theta = np.sin(rotation)\n",
    "    \n",
    "    # Rotate the x and y coordinates to align with the ellipse's axes\n",
    "    x_rot = cos_theta * (x - center[0]) + sin_theta * (y - center[1])\n",
    "    y_rot = -sin_theta * (x - center[0]) + cos_theta * (y - center[1])\n",
    "source\n",
    "    \"\"\"\n",
    "    Generate the pixel coordinates that lie inside an ellipse.\n",
    "\n",
    "    Parameters:\n",
    "    - center: Tuple (x, y) representing the center of the ellipse.\n",
    "    - semi_axes: Tuple (semi_major_axis, semi_minor_axis) representing the lengths of the ellipse's axes.\n",
    "    - rotation: Rotation angle of the ellipse in radians.\n",
    "    - image_shape: Shape of the image (height, width) to constrain the ellipse.\n",
    "\n",
    "    Returns:\n",
    "    - A 2D array of pixel coordinates (row, column) that lie inside the ellipse.\n",
    "    \"\"\"\n",
    "    # Create a grid of x and y coordinates for the image\n",
    "    y, x = np.meshgrid(np.arange(imarray.shape[1]), np.arange(imarray.shape[0]), indexing='xy')\n",
    "    \n",
    "    # Compute the cosine and sine of the rotation angle\n",
    "    cos_theta = np.cos(rotation)\n",
    "    sin_theta = np.sin(rotation)\n",
    "    \n",
    "    # Rotate the x and y coordinates to align with the ellipse's axes\n",
    "    x_rot = cos_theta * (x - center[0]) + sin_theta * (y - center[1])\n",
    "    y_rot = -sin_theta * (x - center[0]) + cos_theta * (y - center[1])\n",
    "\n",
    "    # Create a mask for pixels that lie inside the ellipse\n",
    "    mask = (x_rot / semi_axes[0])**2 + (y_rot / semi_axes[1])**2 <= 1\n",
    "\n",
    "    # Enable interactive mode for Napari (if needed)\n",
    "    settings.application.ipy_interactive = True\n",
    "\n",
    "    # Return the coordinates of the pixels inside the ellipse\n",
    "    return np.column_stack(np.where(mask))\n",
    "\n",
    "def rgb_to_hsv(rgb_array):\n",
    "    \"\"\"\n",
    "    Convert an array of RGB values to HSV (Hue, Saturation, Value).\n",
    "\n",
    "    Parameters:\n",
    "    - rgb_array: A 2D array where each row is an RGB triplet (R, G, B).\n",
    "\n",
    "    Returns:\n",
    "    - A 2D array where each row is an HSV triplet (H, S, V).\n",
    "      H is in degrees (0-360), S and V are percentages (0-100).\n",
    "    \"\"\"\n",
    "    hsv_list = []\n",
    "    for rgb in rgb_array:\n",
    "        r, g, b = rgb  # Extract the RGB components\n",
    "        h, s, v = colorsys.rgb_to_hsv(r, g, b)  # Convert RGB to HSV\n",
    "        hsv_list.append([h * 360, s * 100, v * 100])  # Scale H to degrees, S and V to percentages\n",
    "    return np.array(hsv_list)\n",
    "\n",
    "def csv_to_matrix(file_path):\n",
    "    \"\"\"\n",
    "    Read a CSV file and convert its contents into a matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "    - A 2D list where each row corresponds to a row in the CSV file.\n",
    "    \"\"\"\n",
    "    matrix = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            # Convert numeric values to integers, leave others as strings\n",
    "            matrix.append([int(value) if value.replace('.', '', 1).isdigit() else value for value in row])\n",
    "    return matrix\n",
    "\n",
    "def classify_points(cloud_points, test_points, bandwidth=1.0):\n",
    "    \"\"\"\n",
    "    Classify test points based on their similarity to a cloud of points using Kernel Density Estimation (KDE).\n",
    "\n",
    "    Parameters:\n",
    "    - cloud_points: A 2D array of points representing the training data.\n",
    "    - test_points: A 2D array of points to classify.\n",
    "    - bandwidth: Bandwidth parameter for the KDE (controls smoothness).\n",
    "\n",
    "    Returns:\n",
    "    - A 1D array of probabilities for each test point.\n",
    "    \"\"\"\n",
    "    # Fit a Kernel Density Estimator to the cloud points\n",
    "    kde = KernelDensity(bandwidth=bandwidth, kernel='gaussian')\n",
    "    kde.fit(cloud_points)\n",
    "    \n",
    "    # Evaluate the probability density for each test point\n",
    "    log_density = kde.score_samples(test_points)\n",
    "    \n",
    "    # Convert log-density to probabilities\n",
    "    probabilities = np.exp(log_density)\n",
    "    return probabilities\n",
    "\n",
    "def calibrate_image_resolution(image: np.ndarray):\n",
    "    \"\"\"\n",
    "    Opens a Napari viewer for interactive calibration.\n",
    "    The user draws a line over the scalebar using the Shapes layer (Line)\n",
    "    and presses 'q' to confirm. After the viewer closes the function will\n",
    "    ask for the real-world scalebar length (in Âµm) and return the pixel\n",
    "    resolution in Âµm/pixel.\n",
    "\n",
    "    This function will loop and offer a retry if no line was confirmed\n",
    "    (to avoid the need to re-run the calling cell).\n",
    "    \"\"\"\n",
    "\n",
    "    while True:\n",
    "        viewer = napari.Viewer()\n",
    "        viewer.add_image(image, name='image')\n",
    "        shapes_layer = viewer.add_shapes(name='scalebar', shape_type='line')\n",
    "\n",
    "        # Provide clear on-screen instructions before opening Napari\n",
    "        settings.application.ipy_interactive = False\n",
    "        print(\"\\nðŸŸ¢ Napari opened: draw a line over the scalebar using the Shapes tool (Line).\")\n",
    "        print(\"When finished press 'q' while the Napari window is focused to confirm the measurement.\")\n",
    "\n",
    "        result = {}\n",
    "\n",
    "        @viewer.bind_key('q')\n",
    "        def _on_confirm(event=None):\n",
    "            \"\"\"Callback triggered when 'q' is pressed.\"\"\"\n",
    "            if len(shapes_layer.data) == 0:\n",
    "                print(\"âš ï¸ No line found! Please draw one first and press 'q' again.\")\n",
    "                return\n",
    "            line_coords = shapes_layer.data[0]\n",
    "            p1, p2 = line_coords\n",
    "            pixel_length = np.linalg.norm(p2 - p1)\n",
    "            print(f\"Measured scalebar length: {pixel_length:.2f} pixels\")\n",
    "            result['pixel_length'] = pixel_length\n",
    "            viewer.close()\n",
    "\n",
    "        napari.run()  # Waits until viewer is closed\n",
    "\n",
    "        # If user confirmed a line, proceed to ask for real-world length\n",
    "        if 'pixel_length' in result:\n",
    "            try:\n",
    "                real_length_um = float(input(\"Enter the real-world scalebar length (in Âµm): \"))\n",
    "            except Exception:\n",
    "                raise ValueError(\"Invalid real-world length entered.\")\n",
    "            resolution_um_per_px = real_length_um / result['pixel_length']\n",
    "            print(f\"\\nâœ… Pixel resolution: {resolution_um_per_px:.4f} Âµm/pixel\")\n",
    "            return resolution_um_per_px\n",
    "\n",
    "        # If no line was confirmed, offer a retry to the user\n",
    "        print(\"No scalebar line was confirmed in Napari.\")\n",
    "        retry = input(\"Retry calibration? (y/n): \" ).strip().lower()\n",
    "        if retry != 'y':\n",
    "            raise ValueError(\"Calibration aborted by user. No line was confirmed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f2996d0f-09ef-4401-858f-e9f4a4716db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'ROI' at 0x7279ee626e90>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings.application.ipy_interactive = True\n",
    "\n",
    "# Visualize original, mask, and ROI in Napari\n",
    "viewer_0 = napari.Viewer()\n",
    "\n",
    "viewer_0.add_image(imarray, name='Original', \n",
    "                colormap='grey', blending='additive')\n",
    "viewer_0.add_image(mask_filled, name='Violet', \n",
    "                colormap='green', blending='additive')\n",
    "viewer_0.add_image(ROI_image, name='ROI', \n",
    "                colormap='grey', blending='additive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7927ba-0c56-4ed9-99ca-cb25effaf6e6",
   "metadata": {},
   "source": [
    "After you run the next section, a new Napari window will appear with highlighted in green all the nuclei in the ROI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "20ad51b5-d764-43dc-96b3-5ed19d558a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS 75.0 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Image layer 'Violet' at 0x7279ec1d9ff0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enable interactive mode for Napari\n",
    "settings.application.ipy_interactive = True\n",
    "\n",
    "# Create a copy of the ROI image for processing\n",
    "imarray0 = ROI_image.copy()\n",
    "\n",
    "# Extract the red, green, and blue channels from the ROI image\n",
    "imR = imarray0[:, :, 0]\n",
    "imG = imarray0[:, :, 1]\n",
    "imB = imarray0[:, :, 2]\n",
    "\n",
    "# Convert the training points from RGB to HSV\n",
    "yes_points_hsv = rgb_to_hsv(yes_points)\n",
    "\n",
    "# Scale the HSV training points for better performance in the SVM\n",
    "scaler = StandardScaler()\n",
    "yes_points_scaled = scaler.fit_transform(yes_points_hsv)\n",
    "\n",
    "# Set up the One-Class SVM for anomaly detection\n",
    "sensitivity = 0.8  # Sensitivity level (e.g., 10% of points allowed as outliers)\n",
    "clf = OneClassSVM(kernel='rbf', nu=sensitivity, gamma='scale')\n",
    "clf.fit(yes_points_scaled)\n",
    "\n",
    "# Initialize an empty array for the violet channel\n",
    "imV = np.zeros(np.shape(imR))\n",
    "\n",
    "# Initialize a counter for progress tracking\n",
    "tval = 0\n",
    "\n",
    "# Iterate through the image to classify each pixel\n",
    "for i in range(step, np.shape(imV)[0]):\n",
    "    for j in range(step, np.shape(imV)[1]):\n",
    "        tval += 1\n",
    "        # Process only pixels within the mask\n",
    "        if mask_filled[i, j] > 0:\n",
    "            # Extract RGB values of the current pixel\n",
    "            pR = imR[i, j]\n",
    "            pG = imG[i, j]\n",
    "            pB = imB[i, j]\n",
    "            X = np.array([[pR, pG, pB]])\n",
    "\n",
    "            # Convert the pixel to HSV and scale it\n",
    "            X_hsv = rgb_to_hsv(X)\n",
    "            X_scaled = scaler.transform(X_hsv)\n",
    "\n",
    "            # Classify the pixel using the KDE-based classifier\n",
    "            predictions = classify_points(yes_points, X, bandwidth=20.0)\n",
    "\n",
    "            # Assign the prediction value to the violet channel\n",
    "            if predictions > 0.0:\n",
    "                imV[i, j] = predictions[0]\n",
    "            else:\n",
    "                imV[i, j] = 0\n",
    "        else:\n",
    "            j += step  # Skip to the next step if outside the mask\n",
    "\n",
    "        # Display progress at regular intervals\n",
    "        if (100.0 * tval / (np.shape(imV)[0] * np.shape(imV)[1]) % 1.0 == 0.0):\n",
    "            clear_output(wait=True)\n",
    "            print('PROGRESS ' + str(100.0 * tval / (np.shape(imV)[0] * np.shape(imV)[1])) + ' %')\n",
    "\n",
    "# Visualize the results in Napari\n",
    "viewer_0 = napari.Viewer()\n",
    "\n",
    "# Add the image to the viewer\n",
    "viewer_0.add_image(imarray, name='Original', \n",
    "                colormap='grey', blending='additive')\n",
    "\n",
    "# Add the violet channel (classification results) to the viewer\n",
    "viewer_0.add_image(imV, name='Violet', \n",
    "                   colormap='green', blending='additive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8f25af-4d58-4c29-9974-ebc6bba1ee82",
   "metadata": {},
   "source": [
    "#### Remove noise and big regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "be6f5ae0-301d-454f-a4d1-721659458e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'Violet' at 0x7279e420faf0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualization\n",
    "viewer_full = napari.Viewer()\n",
    "viewer_full.add_image(imarray, name='Original', colormap='grey', blending='additive')\n",
    "viewer_full.add_image(imV, name='Violet', colormap='green', blending='additive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "10fed9f7-9a54-49b2-a8e8-b365326cec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ðŸ”¹ Step 1: Thresholding: switch from grayscale to binary scale (different brightness to either 0 for background or 1 for nuclei)\n",
    "im_in=imV\n",
    "\n",
    "# Get all nonzero values in imV (ignoring background)\n",
    "valid_pixels = imV[imV > 0]  \n",
    "\n",
    "# Compute the percentile threshold only for these valid pixels\n",
    "if len(valid_pixels) > 0:  # Ensure there are nonzero pixels\n",
    "    threshold_value = np.percentile(valid_pixels, 95.0)\n",
    "    strong_th_value = np.percentile(valid_pixels, 98.0)\n",
    "    binary_mask = (imV >= threshold_value)  # Keep only the top 5% brightest pixels\n",
    "    strong_b_mask = (imV >= strong_th_value)  # Keep only the top 5% brightest pixels\n",
    "else:\n",
    "    binary_mask = np.zeros_like(imV)  # If no valid pixels, return empty mask\n",
    "    \n",
    "viewer_full.add_image(binary_mask.astype(float), name=\"Thresholded\", colormap=\"blue\", blending=\"additive\")\n",
    "napari.run()\n",
    "im_out=binary_mask.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5405cdec-b09b-421a-a116-85c6a793da7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Remove Noise & Artifacts\n",
    "im_in=im_out\n",
    "binary_mask=im_in\n",
    "\n",
    "# Remove small objects and close gaps\n",
    "binary_mask2 = remove_small_objects(binary_mask, min_size=5)  \n",
    "binary_mask2 = closing(binary_mask2, square(3))  # Fills small holes and connects nearby white regions.\n",
    "\n",
    "strong_b_mask2 = remove_small_objects(strong_b_mask, min_size=5)  \n",
    "strong_b_mask2 = closing(strong_b_mask2, square(3))  # Fills small holes and connects nearby white regions.\n",
    "\n",
    "viewer_full.add_image(binary_mask2.astype(float), name=\"Noise and art. removed\", colormap=\"blue\", blending=\"additive\")\n",
    "napari.run()\n",
    "im_out=binary_mask2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7c720b64-f2f7-48dc-98e1-e76d30c2fe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Remove Artifacts Based on Size and Roundness\n",
    "im_in=im_out\n",
    "binary_mask2=im_in\n",
    "\n",
    "min_roundness = 0.75\n",
    "\n",
    "# Define the minimum and maximum size for nuclei to be considered valid\n",
    "min_nucleus_diam = 3  # Minimum diameter of a nucleus (um)\n",
    "max_nucleus_diam = 20  # Maximum diameter of a nucleus (um)\n",
    "\n",
    "min_nucleus_diam_res = min_nucleus_diam/((r_X+r_Y)/2)\n",
    "max_nucleus_diam_res = max_nucleus_diam/((r_X+r_Y)/2)\n",
    "\n",
    "min_nucleus_size=(min_nucleus_diam/2)*(min_nucleus_diam/2)*np.pi\n",
    "max_nucleus_size=(max_nucleus_diam/2)*(max_nucleus_diam/2)*np.pi\n",
    "\n",
    "# Initialize an empty mask to store the filtered regions\n",
    "filtered_mask = np.zeros_like(binary_mask2)\n",
    "large_nuclei_mask = filtered_mask.copy()\n",
    "\n",
    "# Iterate through each connected region in the labeled binary mask\n",
    "for region in regionprops(label(binary_mask2)):\n",
    "    # Check if the region's area falls within the valid size range\n",
    "    if min_nucleus_size <= region.area <= max_nucleus_size:\n",
    "        if region.perimeter > 0:\n",
    "            # Compute roundness (circularity)\n",
    "            roundness = 4 * np.pi * region.area / (region.perimeter ** 2)\n",
    "\n",
    "            # Keep only regions that are sufficiently round\n",
    "            if roundness >= min_roundness:\n",
    "                # Add the region to the filtered mask\n",
    "                filtered_mask[label(binary_mask2) == region.label] = 1\n",
    "\n",
    "# Iterate through each connected region in the labeled binary mask\n",
    "for region in regionprops(label(strong_b_mask2)):\n",
    "    # Check if the region's area falls within the valid size range\n",
    "    if min_nucleus_size <= region.area <= max_nucleus_size:\n",
    "        if region.perimeter > 0:\n",
    "            # Compute roundness (circularity)\n",
    "            roundness = 4 * np.pi * region.area / (region.perimeter ** 2)\n",
    "\n",
    "            # Keep only regions that are sufficiently round\n",
    "            if roundness >= min_roundness:\n",
    "                # Add the region to the filtered mask\n",
    "                filtered_mask[label(strong_b_mask2) == region.label] = 1\n",
    "\n",
    "viewer_full.add_image(filtered_mask.astype(float), name=\"Size and roundness threshold\", colormap=\"blue\", blending=\"additive\")\n",
    "napari.run()\n",
    "im_out=filtered_mask.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e7abfc77-da9b-4841-b49b-6b43e0520d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #ðŸ”¹ Step 4: Filter by Size and Roundness\n",
    "# im_in = im_out\n",
    "# segmented_nuclei = im_in\n",
    "\n",
    "# # Define the minimum roundness value (1.0 = perfect circle)\n",
    "# min_roundness = 0.75  # adjust as needed (0.7â€“0.85 works well for nearly round nuclei)\n",
    "\n",
    "# # Initialize an empty mask to store the filtered segments\n",
    "# filtered_segments = np.zeros_like(segmented_nuclei)\n",
    "\n",
    "# # Initialize a counter for assigning new labels to filtered segments\n",
    "# k = 1\n",
    "\n",
    "# # Iterate through each connected region in the segmented nuclei\n",
    "# for region in regionprops(segmented_nuclei):\n",
    "#     if region.perimeter > 0:\n",
    "#         # Compute roundness (circularity)\n",
    "#         roundness = 4 * np.pi * region.area / (region.perimeter ** 2)\n",
    "\n",
    "#         # Keep only regions that are sufficiently round\n",
    "#         if roundness >= min_roundness:\n",
    "#             filtered_segments[segmented_nuclei == region.label] = k\n",
    "#             k += 1\n",
    "\n",
    "# viewer_full.add_labels(filtered_segments, name=\"Filtered by Roundness\")\n",
    "# napari.run()\n",
    "# im_out = filtered_segments.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f88d0c4f-c79e-448e-beed-900b48a28d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Watershed for Better Separation\n",
    "im_in=im_out\n",
    "filtered_mask=im_in\n",
    "\n",
    "# Compute the distance transform of the filtered mask\n",
    "distance = distance_transform_edt(filtered_mask)\n",
    "\n",
    "# Create markers for the watershed algorithm based on the distance transform\n",
    "# Markers are created where the distance is greater than a small fraction of the maximum distance\n",
    "markers = label(distance > 0.0001 * distance.max())\n",
    "\n",
    "# Apply the watershed algorithm to segment nuclei\n",
    "# The negative distance is used to ensure that the watershed grows from the markers\n",
    "segmented_nuclei = watershed(-distance, markers, mask=filtered_mask)\n",
    "\n",
    "viewer_full.add_labels(segmented_nuclei, name=\"Segmented Nuclei\")\n",
    "napari.run()\n",
    "im_out=segmented_nuclei.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d11013-20fa-4c75-aee0-a6d8f24d96f5",
   "metadata": {},
   "source": [
    "### Output \n",
    "Creates a .tiff file with multiple pages. P1 is the original image, P2 is the ROI chosen as the tissue, P3 is the detected nuclei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1fbe0d01-0f21-42d7-8cb8-d83515fe4699",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_segments=segmented_nuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36581240-f960-409c-8557-1c834f4e495e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIFF file saved at: pAC024 D28 uM SafO slide7_output.tiff\n"
     ]
    }
   ],
   "source": [
    "# Convert the original image array to an RGB image\n",
    "rgb_im = Image.fromarray(imarray.astype(np.uint8), mode=\"RGB\")\n",
    "\n",
    "# Convert the ROI image array to an RGB image\n",
    "rgb0_im = Image.fromarray(imarray0.astype(np.uint8), mode=\"RGB\")\n",
    "\n",
    "# Initialize an empty RGB array for the filtered segments\n",
    "filtered_segments_rgb = np.zeros((np.shape(filtered_segments)[0], np.shape(filtered_segments)[1], 3))\n",
    "\n",
    "# Generate random colors for each segment label\n",
    "cmd = np.random.rand(np.max(filtered_segments) + 1, 3)\n",
    "cmd[0, :] = [0.0, 0.0, 0.0]  # Ensure the background (label 0) is black\n",
    "\n",
    "# Assign colors to each pixel based on its segment label\n",
    "for i in range(1, np.shape(filtered_segments)[0]):\n",
    "    for j in range(1, np.shape(filtered_segments)[1]):\n",
    "        filtered_segments_rgb[i, j, 0] = int(cmd[filtered_segments[i, j], 0] * 255.0)  # Red channel\n",
    "        filtered_segments_rgb[i, j, 1] = int(cmd[filtered_segments[i, j], 1] * 255.0)  # Green channel\n",
    "        filtered_segments_rgb[i, j, 2] = int(cmd[filtered_segments[i, j], 2] * 255.0)  # Blue channel\n",
    "\n",
    "# Convert the RGB array to uint8 format\n",
    "filtered_segments_rgb = filtered_segments_rgb.astype('uint8')\n",
    "\n",
    "# Convert the filtered segments RGB array to an image\n",
    "b_im = Image.fromarray(filtered_segments_rgb, mode=\"RGB\")\n",
    "\n",
    "# Save the original image, ROI image, and filtered segments image in a single multi-page TIFF file\n",
    "output_path ='./Output_files/' + tiff_stem + \"_output.tiff\"\n",
    "rgb_im.save(output_path, save_all=True, append_images=[rgb0_im, b_im])\n",
    "\n",
    "# Print the output file path\n",
    "print(f\"TIFF file saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78a6d88-139b-4588-970a-5812cf300484",
   "metadata": {},
   "source": [
    "### QUANTIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "19e43069-f641-4e0e-8434-342420e2e56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL NUCLEI 2166\n",
      "TOTAL AREA IMAGE 3.88e+07 um2\n",
      "TOTAL AREA ROI 5.83e+06 um2\n",
      "CELL CONCENTRATION in ROI 3.71e+02 cells/mm2\n"
     ]
    }
   ],
   "source": [
    "#from scipy.ndimage import label, center_of_mass\n",
    "\n",
    "# Get unique labels from the filtered segments (excluding the background label 0)\n",
    "labels = np.unique(filtered_segments)\n",
    "labels = labels[labels != 0]\n",
    "\n",
    "# Print the total number of nuclei detected\n",
    "print('TOTAL NUCLEI ' + str(len(labels+1)))\n",
    "\n",
    "# Compute the centroids (barycenters) of each nucleus\n",
    "barycenters = {l: center_of_mass(filtered_segments == l) for l in labels}\n",
    "\n",
    "# Compute the area of each nucleus in square micrometers\n",
    "areas = {l: np.sum(filtered_segments == l) * r_X * r_Y for l in labels}\n",
    "\n",
    "# Convert barycenters to a dictionary of coordinates in micrometers\n",
    "barycenter_coords = {k: (round(v[0], 2) * r_X, round(v[1], 2) * r_Y) for k, v in barycenters.items()}\n",
    "\n",
    "# Calculate the total area of the image in square micrometers\n",
    "fullA = np.prod(np.shape(mask_image)) * r_X * r_Y\n",
    "\n",
    "# Calculate the total area of the ROI in square micrometers\n",
    "roiA = np.sum(mask_image) * r_X * r_Y\n",
    "\n",
    "# Print the total area of the image and the ROI\n",
    "print(\"TOTAL AREA IMAGE %.2e um2\" % fullA)\n",
    "print(\"TOTAL AREA ROI %.2e um2\" % roiA)\n",
    "\n",
    "# Calculate the concentration of cells in the ROI (cells per square micrometer)\n",
    "roiCON = (len(labels+1)) / roiA\n",
    "roiCONmm=roiCON*1e6\n",
    "\n",
    "# Print the cell concentration in the ROI\n",
    "print(\"CELL CONCENTRATION in ROI %.2e cells/mm2\" % roiCONmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6d8187-8d56-4473-b7ef-1c98ca4c715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Excel workbook\n",
    "workbook = xlsxwriter.Workbook('./Output_files/' + tiff_stem + '.xlsx')\n",
    "\n",
    "## FORMATS\n",
    "# Define a format for headers (bold text with yellow background)\n",
    "header = workbook.add_format({'bold': True})\n",
    "header.set_bg_color('yellow')\n",
    "\n",
    "# Define a format for floating-point numbers\n",
    "floats = workbook.add_format({'num_format': '0.00'})\n",
    "\n",
    "# Define a format for exponential numbers\n",
    "exp = workbook.add_format()\n",
    "exp.set_num_format(11)\n",
    "\n",
    "## CELLS\n",
    "# Create a worksheet for cell data\n",
    "worksheet_cell = workbook.add_worksheet('Cells')\n",
    "\n",
    "# HEADER\n",
    "# Write the header row for the 'Cells' worksheet\n",
    "worksheet_cell.write_row('A1:E1', ['#ID', 'X [um]', 'Y [um]', 'Area Nuclei [um2]'], header)\n",
    "\n",
    "# CONTENT\n",
    "# Write the data for each nucleus\n",
    "for row, value in enumerate(labels):\n",
    "    worksheet_cell.write(row + 1, 0, value)  # Write nucleus ID\n",
    "    worksheet_cell.write(row + 1, 1, barycenter_coords[value][0], floats)  # Write X coordinate\n",
    "    worksheet_cell.write(row + 1, 2, barycenter_coords[value][1], floats)  # Write Y coordinate\n",
    "    worksheet_cell.write(row + 1, 3, areas[value], floats)  # Write area of the nucleus\n",
    "    clear_output(wait=True)  # Clear the output to show progress\n",
    "    print('NUCLEI ' + str(row + 1) + ' / ' + str(len(labels + 1)))  # Print progress\n",
    "\n",
    "## ROI SHEET\n",
    "# Create a worksheet for ROI data\n",
    "worksheet_ROI = workbook.add_worksheet('ROI')\n",
    "\n",
    "# HEADER\n",
    "# Write the header row for the 'ROI' worksheet\n",
    "worksheet_ROI.write_row('A1:E1', ['# NUCLEI', 'TOT AREA [um2]', 'ROI AREA [um2]', 'CONC NUCLEI in ROI [cells/mm2]'], header)\n",
    "\n",
    "# CONTENT\n",
    "# Write the ROI data\n",
    "worksheet_ROI.write(1, 0, len(labels + 1))  # Write the total number of nuclei\n",
    "worksheet_ROI.write(1, 1, fullA, exp)  # Write the total area of the image\n",
    "worksheet_ROI.write(1, 2, roiA, exp)  # Write the total area of the ROI\n",
    "worksheet_ROI.write(1, 3, roiCONmm, exp)  # Write the cell concentration in the ROI\n",
    "\n",
    "# Close the workbook to save the file\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c18e04-f518-4af6-b31b-9d670de8a79f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
